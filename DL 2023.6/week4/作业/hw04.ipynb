{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ldm2060/LearningNote/blob/main/DL%202023.6/week4/%E4%BD%9C%E4%B8%9A/hw04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task description\n",
        "- Classify the speakers of given features.\n",
        "- Main goal: Learn how to use transformer.\n",
        "- Baselines:\n",
        "  - Easy: Run sample code and know how to use transformer.\n",
        "  - Medium: Know how to adjust parameters of transformer.\n",
        "  - Strong: Construct [conformer](https://arxiv.org/abs/2005.08100) which is a variety of transformer.\n",
        "  - Boss: Implement [Self-Attention Pooling](https://arxiv.org/pdf/2008.01077v1.pdf) & [Additive Margin Softmax](https://arxiv.org/pdf/1801.05599.pdf) to further boost the performance.\n",
        "\n",
        "- Other links\n",
        "  - Kaggle: [link](https://www.kaggle.com/t/ac77388c90204a4c8daebeddd40ff916)\n",
        "  - Slide: [link](https://docs.google.com/presentation/d/1HLAj7UUIjZOycDe7DaVLSwJfXVd3bXPOyzSb6Zk3hYU/edit?usp=sharing)\n",
        "  - Data: [link](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)\n",
        "\n",
        "# Download dataset\n",
        "- Data is [here](https://drive.google.com/drive/folders/1vI1kuLB-q1VilIftiwnPOCAeOOFfBZge?usp=sharing)"
      ],
      "metadata": {
        "id": "C_jdZ5vHJ4A9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partaa\n",
        "#!wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partab\n",
        "#!wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partac\n",
        "#!wget https://github.com/MachineLearningHW/ML_HW4_Dataset/releases/latest/download/Dataset.tar.gz.partad\n",
        "\n",
        "#!cat Dataset.tar.gz.part* > Dataset.tar.gz\n",
        "\n",
        "# unzip the file\n",
        "#!tar zxvf Dataset.tar.gz"
      ],
      "metadata": {
        "id": "LhLNWB-AK2Z5",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:13.911683Z",
          "iopub.execute_input": "2023-07-15T07:40:13.912150Z",
          "iopub.status.idle": "2023-07-15T07:40:13.919011Z",
          "shell.execute_reply.started": "2023-07-15T07:40:13.912116Z",
          "shell.execute_reply": "2023-07-15T07:40:13.917866Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fix Random Seed"
      ],
      "metadata": {
        "id": "ENWVAUDVJtVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Conformer\n",
        "from conformer import ConformerBlock\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "\n",
        "def set_seed(seed):\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed(seed)\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "set_seed(87)"
      ],
      "metadata": {
        "id": "E6burzCXIyuA",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:13.921548Z",
          "iopub.execute_input": "2023-07-15T07:40:13.922306Z",
          "iopub.status.idle": "2023-07-15T07:40:25.614754Z",
          "shell.execute_reply.started": "2023-07-15T07:40:13.922268Z",
          "shell.execute_reply": "2023-07-15T07:40:25.613521Z"
        },
        "trusted": true,
        "outputId": "c64cc4ec-7be5-4fad-dfd2-89e869cea8b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: Conformer in /opt/conda/lib/python3.10/site-packages (0.3.2)\nRequirement already satisfied: einops>=0.6.1 in /opt/conda/lib/python3.10/site-packages (from Conformer) (0.6.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from Conformer) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->Conformer) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->Conformer) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->Conformer) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->Conformer) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->Conformer) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->Conformer) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->Conformer) (1.3.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "\n",
        "## Dataset\n",
        "- Original dataset is [Voxceleb2](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/vox2.html).\n",
        "- The [license](https://creativecommons.org/licenses/by/4.0/) and [complete version](https://www.robots.ox.ac.uk/~vgg/data/voxceleb/files/license.txt) of Voxceleb2.\n",
        "- We randomly select 600 speakers from Voxceleb2.\n",
        "- Then preprocess the raw waveforms into mel-spectrograms.\n",
        "\n",
        "- Args:\n",
        "  - data_dir: The path to the data directory.\n",
        "  - metadata_path: The path to the metadata.\n",
        "  - segment_len: The length of audio segment for training.\n",
        "- The architecture of data directory \\\\\n",
        "  - data directory \\\\\n",
        "  |---- metadata.json \\\\\n",
        "  |---- testdata.json \\\\\n",
        "  |---- mapping.json \\\\\n",
        "  |---- uttr-{random string}.pt \\\\\n",
        "\n",
        "- The information in metadata\n",
        "  - \"n_mels\": The dimention of mel-spectrogram.\n",
        "  - \"speakers\": A dictionary.\n",
        "    - Key: speaker ids.\n",
        "    - value: \"feature_path\" and \"mel_len\"\n",
        "\n",
        "\n",
        "For efficiency, we segment the mel-spectrograms into segments in the traing step."
      ],
      "metadata": {
        "id": "k7dVbxW2LASN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "class myDataset(Dataset):\n",
        "\tdef __init__(self, data_dir, segment_len=128):\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.segment_len = segment_len\n",
        "\n",
        "\t\t# Load the mapping from speaker neme to their corresponding id.\n",
        "\t\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\t\tmapping = json.load(mapping_path.open())\n",
        "\t\tself.speaker2id = mapping[\"speaker2id\"]\n",
        "\n",
        "\t\t# Load metadata of training data.\n",
        "\t\tmetadata_path = Path(data_dir) / \"metadata.json\"\n",
        "\t\tmetadata = json.load(open(metadata_path))[\"speakers\"]\n",
        "\n",
        "\t\t# Get the total number of speaker.\n",
        "\t\tself.speaker_num = len(metadata.keys())\n",
        "\t\tself.data = []\n",
        "\t\tfor speaker in metadata.keys():\n",
        "\t\t\tfor utterances in metadata[speaker]:\n",
        "\t\t\t\tself.data.append([utterances[\"feature_path\"], self.speaker2id[speaker]])\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tfeat_path, speaker = self.data[index]\n",
        "\t\t# Load preprocessed mel-spectrogram.\n",
        "\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "\t\t# Segmemt mel-spectrogram into \"segment_len\" frames.\n",
        "\t\tif len(mel) > self.segment_len:\n",
        "\t\t\t# Randomly get the starting point of the segment.\n",
        "\t\t\tstart = random.randint(0, len(mel) - self.segment_len)\n",
        "\t\t\t# Get a segment with \"segment_len\" frames.\n",
        "\t\t\tmel = torch.FloatTensor(mel[start:start+self.segment_len])\n",
        "\t\telse:\n",
        "\t\t\tmel = torch.FloatTensor(mel)\n",
        "\t\t# Turn the speaker id into long for computing loss later.\n",
        "\t\tspeaker = torch.FloatTensor([speaker]).long()\n",
        "\t\treturn mel, speaker\n",
        "\n",
        "\tdef get_speaker_number(self):\n",
        "\t\treturn self.speaker_num"
      ],
      "metadata": {
        "id": "KpuGxl4CI2pr",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.617562Z",
          "iopub.execute_input": "2023-07-15T07:40:25.617961Z",
          "iopub.status.idle": "2023-07-15T07:40:25.630238Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.617923Z",
          "shell.execute_reply": "2023-07-15T07:40:25.629320Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloader\n",
        "- Split dataset into training dataset(90%) and validation dataset(10%).\n",
        "- Create dataloader to iterate the data."
      ],
      "metadata": {
        "id": "668hverTMlGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "\n",
        "def collate_batch(batch):\n",
        "\t# Process features within a batch.\n",
        "\t\"\"\"Collate a batch of data.\"\"\"\n",
        "\tmel, speaker = zip(*batch)\n",
        "\t# Because we train the model batch by batch, we need to pad the features in the same batch to make their lengths the same.\n",
        "\tmel = pad_sequence(mel, batch_first=True, padding_value=-20)    # pad log 10^(-20) which is very small value.\n",
        "\t# mel: (batch size, length, 40)\n",
        "\treturn mel, torch.FloatTensor(speaker).long()\n",
        "\n",
        "\n",
        "def get_dataloader(data_dir, batch_size, n_workers):\n",
        "\t\"\"\"Generate dataloader\"\"\"\n",
        "\tdataset = myDataset(data_dir)\n",
        "\tspeaker_num = dataset.get_speaker_number()\n",
        "\t# Split dataset into training dataset and validation dataset\n",
        "\ttrainlen = int(0.9 * len(dataset))\n",
        "\tlengths = [trainlen, len(dataset) - trainlen]\n",
        "\ttrainset, validset = random_split(dataset, lengths)\n",
        "\n",
        "\ttrain_loader = DataLoader(\n",
        "\t\ttrainset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tshuffle=True,\n",
        "\t\tdrop_last=True,\n",
        "\t\tnum_workers=n_workers,\n",
        "\t\tpin_memory=True,\n",
        "\t\tcollate_fn=collate_batch,\n",
        "\t)\n",
        "\tvalid_loader = DataLoader(\n",
        "\t\tvalidset,\n",
        "\t\tbatch_size=batch_size,\n",
        "\t\tnum_workers=n_workers,\n",
        "\t\tdrop_last=True,\n",
        "\t\tpin_memory=True,\n",
        "\t\tcollate_fn=collate_batch,\n",
        "\t)\n",
        "\n",
        "\treturn train_loader, valid_loader, speaker_num"
      ],
      "metadata": {
        "id": "B7c2gZYoJDRS",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.631596Z",
          "iopub.execute_input": "2023-07-15T07:40:25.631925Z",
          "iopub.status.idle": "2023-07-15T07:40:25.648373Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.631892Z",
          "shell.execute_reply": "2023-07-15T07:40:25.647501Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class SelfAttentionPooling(nn.Module):\n",
        "\tdef __init__(self, input_dim):\n",
        "\t\tsuper(SelfAttentionPooling, self).__init__()\n",
        "\t\tself.sap_linaer = nn.Linear(input_dim, input_dim)\n",
        "\t\tself.attention = nn.Parameter(torch.FloatTensor(input_dim,1))\n",
        "\t\ttorch.nn.init.normal_(self.attention, std=.02)\n",
        "\n",
        "\tdef forward(self, x):\n",
        "\t\t# x = x.permute(0, 2, 1)\n",
        "\t\th = torch.tanh(self.sap_linaer(x))\n",
        "\t\tw = torch.matmul(h, self.attention).squeeze(dim=2)\n",
        "\t\tw = F.softmax(w, dim=1).view(x.size(0), x.size(1), 1)\n",
        "\t\tx = torch.sum(x * w, dim=1)\n",
        "\t\treturn x\n",
        "\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "\tdef __init__(self, d_model=256, n_spks=600, dropout=0.1):\n",
        "\t\tsuper().__init__()\n",
        "\t\t# Project the dimension of features from that of input into d_model.\n",
        "\t\tself.prenet = nn.Linear(40, d_model)\n",
        "\t\t# TODO:\n",
        "\t\t#   Change Transformer to Conformer.\n",
        "\t\t#   https://arxiv.org/abs/2005.08100\n",
        "\t\tself.encoder_layer = nn.TransformerEncoderLayer(\n",
        "\t\t\td_model=d_model, dim_feedforward=256, nhead=1\n",
        "\t\t)\n",
        "\t\tself.encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=2)\n",
        "\t\tself.blocks = nn.ModuleList([\n",
        "\t\t\tConformerBlock(\n",
        "\t\t\t\tdim=d_model,\n",
        "\t\t\t\tdim_head=64,\n",
        "\t\t\t\theads=8,\n",
        "\t\t\t\tff_mult=4,\n",
        "\t\t\t\tconv_expansion_factor=2,\n",
        "\t\t\t\tconv_kernel_size=15,\n",
        "\t\t\t\tattn_dropout=dropout,\n",
        "\t\t\t\tff_dropout=dropout,\n",
        "\t\t\t\tconv_dropout=dropout\n",
        "\t\t\t)\n",
        "\t\t\tfor i in range(6)])\n",
        "\n",
        "\t\t# Project the the dimension of features from d_model into speaker nums.\n",
        "\t\tself.pred_layer = nn.Sequential(\n",
        "\t\t\t#nn.Linear(d_model, d_model),\n",
        "\t\t\tnn.ReLU(),\n",
        "\t\t\tnn.Linear(d_model, n_spks),\n",
        "\t\t)\n",
        "\t\tself.pooling = SelfAttentionPooling(d_model)\n",
        "\n",
        "\tdef forward(self, mels):\n",
        "\t\t\"\"\"\n",
        "\t\targs:\n",
        "\t\t\tmels: (batch size, length, 40)\n",
        "\t\treturn:\n",
        "\t\t\tout: (batch size, n_spks)\n",
        "\t\t\"\"\"\n",
        "\t\t# out: (batch size, length, d_model)\n",
        "\t\tout = self.prenet(mels)\n",
        "\t\t# out: (length, batch size, d_model)\n",
        "\t\tout = out.permute(1, 0, 2)\n",
        "\t\t# The encoder layer expect features in the shape of (length, batch size, d_model).\n",
        "\t\tout = self.encoder_layer(out)\n",
        "\t\t#out: (batch size, length, d_model)\n",
        "\t\tout = out.transpose(0, 1)\n",
        "\t\t#for blk in self.blocks:\n",
        "\t\t#\tout = blk(out)\n",
        "\t\t# mean pooling\n",
        "\t\t#stats = out.mean(dim=1)\n",
        "\t\tstats = self.pooling(out)\n",
        "\t\t# out: (batch, n_spks)\n",
        "\t\tout = self.pred_layer(stats)\n",
        "\t\treturn out"
      ],
      "metadata": {
        "id": "iXZ5B0EKJGs8",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.651561Z",
          "iopub.execute_input": "2023-07-15T07:40:25.651888Z",
          "iopub.status.idle": "2023-07-15T07:40:25.666900Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.651858Z",
          "shell.execute_reply": "2023-07-15T07:40:25.665783Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "- TransformerEncoderLayer:\n",
        "  - Base transformer encoder layer in [Attention Is All You Need](https://arxiv.org/abs/1706.03762)\n",
        "  - Parameters:\n",
        "    - d_model: the number of expected features of the input (required).\n",
        "\n",
        "    - nhead: the number of heads of the multiheadattention models (required).\n",
        "\n",
        "    - dim_feedforward: the dimension of the feedforward network model (default=2048).\n",
        "\n",
        "    - dropout: the dropout value (default=0.1).\n",
        "\n",
        "    - activation: the activation function of intermediate layer, relu or gelu (default=relu).\n",
        "\n",
        "- TransformerEncoder:\n",
        "  - TransformerEncoder is a stack of N transformer encoder layers\n",
        "  - Parameters:\n",
        "    - encoder_layer: an instance of the TransformerEncoderLayer() class (required).\n",
        "\n",
        "    - num_layers: the number of sub-encoder-layers in the encoder (required).\n",
        "\n",
        "    - norm: the layer normalization component (optional)."
      ],
      "metadata": {
        "id": "5FOSZYxrMqhc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning rate schedule\n",
        "- For transformer architecture, the design of learning rate schedule is different from that of CNN.\n",
        "- Previous works show that the warmup of learning rate is useful for training models with transformer architectures.\n",
        "- The warmup schedule\n",
        "  - Set learning rate to 0 in the beginning.\n",
        "  - The learning rate increases linearly from 0 to initial learning rate during warmup period."
      ],
      "metadata": {
        "id": "W7yX8JinM5Ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LambdaLR\n",
        "\n",
        "\n",
        "def get_cosine_schedule_with_warmup(\n",
        "\toptimizer: Optimizer,\n",
        "\tnum_warmup_steps: int,\n",
        "\tnum_training_steps: int,\n",
        "\tnum_cycles: float = 0.5,\n",
        "\tlast_epoch: int = -1,\n",
        "):\n",
        "\t\"\"\"\n",
        "\tCreate a schedule with a learning rate that decreases following the values of the cosine function between the\n",
        "\tinitial lr set in the optimizer to 0, after a warmup period during which it increases linearly between 0 and the\n",
        "\tinitial lr set in the optimizer.\n",
        "\n",
        "\tArgs:\n",
        "\t\toptimizer (:class:`~torch.optim.Optimizer`):\n",
        "\t\tThe optimizer for which to schedule the learning rate.\n",
        "\t\tnum_warmup_steps (:obj:`int`):\n",
        "\t\tThe number of steps for the warmup phase.\n",
        "\t\tnum_training_steps (:obj:`int`):\n",
        "\t\tThe total number of training steps.\n",
        "\t\tnum_cycles (:obj:`float`, `optional`, defaults to 0.5):\n",
        "\t\tThe number of waves in the cosine schedule (the defaults is to just decrease from the max value to 0\n",
        "\t\tfollowing a half-cosine).\n",
        "\t\tlast_epoch (:obj:`int`, `optional`, defaults to -1):\n",
        "\t\tThe index of the last epoch when resuming training.\n",
        "\n",
        "\tReturn:\n",
        "\t\t:obj:`torch.optim.lr_scheduler.LambdaLR` with the appropriate schedule.\n",
        "\t\"\"\"\n",
        "\tdef lr_lambda(current_step):\n",
        "\t\t# Warmup\n",
        "\t\tif current_step < num_warmup_steps:\n",
        "\t\t\treturn float(current_step) / float(max(1, num_warmup_steps))\n",
        "\t\t# decadence\n",
        "\t\tprogress = float(current_step - num_warmup_steps) / float(\n",
        "\t\t\tmax(1, num_training_steps - num_warmup_steps)\n",
        "\t\t)\n",
        "\t\treturn max(\n",
        "\t\t\t0.0, 0.5 * (1.0 + math.cos(math.pi * float(num_cycles) * 2.0 * progress))\n",
        "\t\t)\n",
        "\n",
        "\treturn LambdaLR(optimizer, lr_lambda, last_epoch)"
      ],
      "metadata": {
        "id": "ykt0N1nVJJi2",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.668877Z",
          "iopub.execute_input": "2023-07-15T07:40:25.669219Z",
          "iopub.status.idle": "2023-07-15T07:40:25.683592Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.669188Z",
          "shell.execute_reply": "2023-07-15T07:40:25.682627Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Function\n",
        "- Model forward function."
      ],
      "metadata": {
        "id": "-LN2XkteM_uH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "\n",
        "def model_fn(batch, model, criterion, device):\n",
        "\t\"\"\"Forward a batch through the model.\"\"\"\n",
        "\n",
        "\tmels, labels = batch\n",
        "\tmels = mels.to(device)\n",
        "\tlabels = labels.to(device)\n",
        "\n",
        "\touts = model(mels)\n",
        "\n",
        "\tloss = criterion(outs, labels)\n",
        "\n",
        "\t# Get the speaker id with highest probability.\n",
        "\tpreds = outs.argmax(1)\n",
        "\t# Compute accuracy.\n",
        "\taccuracy = torch.mean((preds == labels).float())\n",
        "\n",
        "\treturn loss, accuracy"
      ],
      "metadata": {
        "id": "N-rr8529JMz0",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.685160Z",
          "iopub.execute_input": "2023-07-15T07:40:25.685504Z",
          "iopub.status.idle": "2023-07-15T07:40:25.697919Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.685473Z",
          "shell.execute_reply": "2023-07-15T07:40:25.696959Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validate\n",
        "- Calculate accuracy of the validation set."
      ],
      "metadata": {
        "id": "cwM_xyOtNCI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import torch\n",
        "\n",
        "\n",
        "def valid(dataloader, model, criterion, device):\n",
        "\t\"\"\"Validate on validation set.\"\"\"\n",
        "\n",
        "\tmodel.eval()\n",
        "\trunning_loss = 0.0\n",
        "\trunning_accuracy = 0.0\n",
        "\tpbar = tqdm(total=len(dataloader.dataset), ncols=0, desc=\"Valid\", unit=\" uttr\")\n",
        "\n",
        "\tfor i, batch in enumerate(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n",
        "\t\t\trunning_loss += loss.item()\n",
        "\t\t\trunning_accuracy += accuracy.item()\n",
        "\n",
        "\t\tpbar.update(dataloader.batch_size)\n",
        "\t\tpbar.set_postfix(\n",
        "\t\t\tloss=f\"{running_loss / (i+1):.2f}\",\n",
        "\t\t\taccuracy=f\"{running_accuracy / (i+1):.2f}\",\n",
        "\t\t)\n",
        "\n",
        "\tpbar.close()\n",
        "\tmodel.train()\n",
        "\n",
        "\treturn running_accuracy / len(dataloader)"
      ],
      "metadata": {
        "id": "YAiv6kpdJRTJ",
        "execution": {
          "iopub.status.busy": "2023-07-15T07:40:25.699408Z",
          "iopub.execute_input": "2023-07-15T07:40:25.699777Z",
          "iopub.status.idle": "2023-07-15T07:40:25.710224Z",
          "shell.execute_reply.started": "2023-07-15T07:40:25.699745Z",
          "shell.execute_reply": "2023-07-15T07:40:25.709219Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main function"
      ],
      "metadata": {
        "id": "g6ne9G-eNEdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"/kaggle/input/ml2022spring-hw4/Dataset\",\n",
        "\t\t\"save_path\": \"/kaggle/working/model.ckpt\",\n",
        "\t\t\"batch_size\": 32,\n",
        "\t\t\"n_workers\": 2,\n",
        "\t\t\"valid_steps\": 2000,\n",
        "\t\t\"warmup_steps\": 1000,\n",
        "\t\t\"save_steps\": 10000,\n",
        "\t\t\"total_steps\": 140000,\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tsave_path,\n",
        "\tbatch_size,\n",
        "\tn_workers,\n",
        "\tvalid_steps,\n",
        "\twarmup_steps,\n",
        "\ttotal_steps,\n",
        "\tsave_steps,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\ttrain_loader, valid_loader, speaker_num = get_dataloader(data_dir, batch_size, n_workers)\n",
        "\ttrain_iterator = iter(train_loader)\n",
        "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
        "\tcriterion = nn.CrossEntropyLoss()\n",
        "\toptimizer = AdamW(model.parameters(), lr=1e-3)\n",
        "\tscheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\tbest_accuracy = -1.0\n",
        "\tbest_state_dict = None\n",
        "\n",
        "\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "\tfor step in range(total_steps):\n",
        "\t\t# Get data\n",
        "\t\ttry:\n",
        "\t\t\tbatch = next(train_iterator)\n",
        "\t\texcept StopIteration:\n",
        "\t\t\ttrain_iterator = iter(train_loader)\n",
        "\t\t\tbatch = next(train_iterator)\n",
        "\n",
        "\t\tloss, accuracy = model_fn(batch, model, criterion, device)\n",
        "\t\tbatch_loss = loss.item()\n",
        "\t\tbatch_accuracy = accuracy.item()\n",
        "\n",
        "\t\t# Updata model\n",
        "\t\tloss.backward()\n",
        "\t\toptimizer.step()\n",
        "\t\tscheduler.step()\n",
        "\t\toptimizer.zero_grad()\n",
        "\n",
        "\t\t# Log\n",
        "\t\tpbar.update()\n",
        "\t\tpbar.set_postfix(\n",
        "\t\t\tloss=f\"{batch_loss:.2f}\",\n",
        "\t\t\taccuracy=f\"{batch_accuracy:.2f}\",\n",
        "\t\t\tstep=step + 1,\n",
        "\t\t)\n",
        "\n",
        "\t\t# Do validation\n",
        "\t\tif (step + 1) % valid_steps == 0:\n",
        "\t\t\tpbar.close()\n",
        "\n",
        "\t\t\tvalid_accuracy = valid(valid_loader, model, criterion, device)\n",
        "\n",
        "\t\t\t# keep the best model\n",
        "\t\t\tif valid_accuracy > best_accuracy:\n",
        "\t\t\t\tbest_accuracy = valid_accuracy\n",
        "\t\t\t\tbest_state_dict = model.state_dict()\n",
        "\n",
        "\t\t\tpbar = tqdm(total=valid_steps, ncols=0, desc=\"Train\", unit=\" step\")\n",
        "\n",
        "\t\t# Save the best model so far.\n",
        "\t\tif (step + 1) % save_steps == 0 and best_state_dict is not None:\n",
        "\t\t\ttorch.save(best_state_dict, save_path)\n",
        "\t\t\tpbar.write(f\"Step {step + 1}, best model saved. (accuracy={best_accuracy:.4f})\")\n",
        "\n",
        "\tpbar.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(**parse_args())"
      ],
      "metadata": {
        "id": "Usv9s-CuJSG7",
        "execution": {
          "iopub.status.busy": "2023-07-15T08:12:06.372868Z",
          "iopub.execute_input": "2023-07-15T08:12:06.373327Z",
          "iopub.status.idle": "2023-07-15T09:12:53.561866Z",
          "shell.execute_reply.started": "2023-07-15T08:12:06.373273Z",
          "shell.execute_reply": "2023-07-15T09:12:53.560839Z"
        },
        "trusted": true,
        "outputId": "091bb064-98aa-4bed-f17d-f314ee037150"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[Info]: Use cuda now!\n[Info]: Finish loading data!\n[Info]: Finish creating model!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [01:03<00:00, 31.74 step/s, accuracy=0.28, loss=3.83, step=2000]\nValid: 100% 5664/5667 [00:03<00:00, 1455.11 uttr/s, accuracy=0.23, loss=3.60]\nTrain: 100% 2000/2000 [00:49<00:00, 40.70 step/s, accuracy=0.28, loss=3.03, step=4000]\nValid: 100% 5664/5667 [00:03<00:00, 1502.29 uttr/s, accuracy=0.36, loss=2.92]\nTrain: 100% 2000/2000 [00:45<00:00, 43.94 step/s, accuracy=0.53, loss=2.30, step=6000]\nValid: 100% 5664/5667 [00:03<00:00, 1520.36 uttr/s, accuracy=0.43, loss=2.55]\nTrain: 100% 2000/2000 [00:44<00:00, 44.65 step/s, accuracy=0.44, loss=2.52, step=8000]\nValid: 100% 5664/5667 [00:03<00:00, 1556.40 uttr/s, accuracy=0.47, loss=2.32]\nTrain: 100% 2000/2000 [00:44<00:00, 44.62 step/s, accuracy=0.41, loss=2.48, step=1e+4]\nValid: 100% 5664/5667 [00:03<00:00, 1417.24 uttr/s, accuracy=0.50, loss=2.24]\nTrain:   0% 10/2000 [00:00<01:06, 29.93 step/s, accuracy=0.31, loss=3.34, step=1e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 10000, best model saved. (accuracy=0.5011)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:45<00:00, 44.34 step/s, accuracy=0.53, loss=1.57, step=12000]\nValid: 100% 5664/5667 [00:03<00:00, 1436.01 uttr/s, accuracy=0.52, loss=2.12]\nTrain: 100% 2000/2000 [00:44<00:00, 44.63 step/s, accuracy=0.53, loss=1.97, step=14000]\nValid: 100% 5664/5667 [00:03<00:00, 1530.75 uttr/s, accuracy=0.53, loss=2.11]\nTrain: 100% 2000/2000 [00:50<00:00, 39.40 step/s, accuracy=0.75, loss=1.28, step=16000]\nValid: 100% 5664/5667 [00:04<00:00, 1201.05 uttr/s, accuracy=0.57, loss=1.93]\nTrain: 100% 2000/2000 [00:45<00:00, 44.25 step/s, accuracy=0.69, loss=1.38, step=18000]\nValid: 100% 5664/5667 [00:03<00:00, 1418.70 uttr/s, accuracy=0.58, loss=1.87]\nTrain: 100% 2000/2000 [00:44<00:00, 44.88 step/s, accuracy=0.56, loss=1.62, step=2e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1490.74 uttr/s, accuracy=0.60, loss=1.74]\nTrain:   1% 11/2000 [00:00<00:55, 35.61 step/s, accuracy=0.59, loss=1.40, step=2e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 20000, best model saved. (accuracy=0.5960)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:45<00:00, 43.82 step/s, accuracy=0.72, loss=1.00, step=22000]\nValid: 100% 5664/5667 [00:03<00:00, 1517.38 uttr/s, accuracy=0.60, loss=1.73]\nTrain: 100% 2000/2000 [00:45<00:00, 43.81 step/s, accuracy=0.72, loss=1.00, step=24000]\nValid: 100% 5664/5667 [00:03<00:00, 1433.29 uttr/s, accuracy=0.61, loss=1.70]\nTrain: 100% 2000/2000 [00:45<00:00, 43.90 step/s, accuracy=0.78, loss=1.26, step=26000]\nValid: 100% 5664/5667 [00:03<00:00, 1491.98 uttr/s, accuracy=0.62, loss=1.67]\nTrain: 100% 2000/2000 [00:45<00:00, 44.42 step/s, accuracy=0.78, loss=1.44, step=28000]\nValid: 100% 5664/5667 [00:03<00:00, 1519.86 uttr/s, accuracy=0.64, loss=1.62]\nTrain: 100% 2000/2000 [00:45<00:00, 43.91 step/s, accuracy=0.81, loss=0.83, step=3e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1476.10 uttr/s, accuracy=0.64, loss=1.61]\nTrain:   1% 11/2000 [00:00<00:54, 36.46 step/s, accuracy=0.69, loss=1.29, step=3e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 30000, best model saved. (accuracy=0.6419)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:44<00:00, 44.55 step/s, accuracy=0.75, loss=0.95, step=32000]\nValid: 100% 5664/5667 [00:04<00:00, 1353.49 uttr/s, accuracy=0.64, loss=1.57]\nTrain: 100% 2000/2000 [00:45<00:00, 44.32 step/s, accuracy=0.78, loss=0.83, step=34000]\nValid: 100% 5664/5667 [00:03<00:00, 1542.26 uttr/s, accuracy=0.65, loss=1.52]\nTrain: 100% 2000/2000 [00:45<00:00, 43.85 step/s, accuracy=0.66, loss=1.11, step=36000]\nValid: 100% 5664/5667 [00:03<00:00, 1525.20 uttr/s, accuracy=0.66, loss=1.52]\nTrain: 100% 2000/2000 [00:54<00:00, 36.59 step/s, accuracy=0.62, loss=1.44, step=38000]\nValid: 100% 5664/5667 [00:04<00:00, 1325.89 uttr/s, accuracy=0.64, loss=1.56]\nTrain: 100% 2000/2000 [00:45<00:00, 44.14 step/s, accuracy=0.75, loss=1.44, step=4e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1562.09 uttr/s, accuracy=0.67, loss=1.45]\nTrain:   1% 11/2000 [00:00<00:55, 35.83 step/s, accuracy=0.84, loss=0.63, step=4e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 40000, best model saved. (accuracy=0.6651)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:45<00:00, 43.57 step/s, accuracy=0.75, loss=0.96, step=42000]\nValid: 100% 5664/5667 [00:07<00:00, 770.78 uttr/s, accuracy=0.68, loss=1.43] \nTrain: 100% 2000/2000 [01:03<00:00, 31.60 step/s, accuracy=0.75, loss=0.76, step=44000]\nValid: 100% 5664/5667 [00:03<00:00, 1539.57 uttr/s, accuracy=0.67, loss=1.41]\nTrain: 100% 2000/2000 [00:47<00:00, 42.15 step/s, accuracy=0.69, loss=1.35, step=46000]\nValid: 100% 5664/5667 [00:04<00:00, 1356.19 uttr/s, accuracy=0.69, loss=1.34]\nTrain: 100% 2000/2000 [00:45<00:00, 44.02 step/s, accuracy=0.75, loss=0.75, step=48000]\nValid: 100% 5664/5667 [00:03<00:00, 1490.00 uttr/s, accuracy=0.69, loss=1.33]\nTrain: 100% 2000/2000 [00:50<00:00, 39.72 step/s, accuracy=0.84, loss=0.73, step=5e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1485.69 uttr/s, accuracy=0.70, loss=1.33]\nTrain:   1% 11/2000 [00:00<00:53, 37.43 step/s, accuracy=0.72, loss=0.79, step=5e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 50000, best model saved. (accuracy=0.7027)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:56<00:00, 35.14 step/s, accuracy=0.81, loss=0.79, step=52000]\nValid: 100% 5664/5667 [00:04<00:00, 1174.34 uttr/s, accuracy=0.69, loss=1.35]\nTrain: 100% 2000/2000 [00:55<00:00, 35.91 step/s, accuracy=0.75, loss=1.31, step=54000]\nValid: 100% 5664/5667 [00:03<00:00, 1425.52 uttr/s, accuracy=0.71, loss=1.29]\nTrain: 100% 2000/2000 [00:56<00:00, 35.67 step/s, accuracy=0.75, loss=0.85, step=56000]\nValid: 100% 5664/5667 [00:04<00:00, 1305.33 uttr/s, accuracy=0.70, loss=1.30]\nTrain: 100% 2000/2000 [00:55<00:00, 35.90 step/s, accuracy=0.91, loss=0.44, step=58000]\nValid: 100% 5664/5667 [00:04<00:00, 1386.80 uttr/s, accuracy=0.72, loss=1.27]\nTrain: 100% 2000/2000 [00:57<00:00, 34.70 step/s, accuracy=0.81, loss=0.85, step=6e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1452.81 uttr/s, accuracy=0.71, loss=1.28]\nTrain:   0% 8/2000 [00:00<01:14, 26.89 step/s, accuracy=0.81, loss=0.44, step=6e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 60000, best model saved. (accuracy=0.7188)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:56<00:00, 35.37 step/s, accuracy=0.72, loss=0.85, step=62000]\nValid: 100% 5664/5667 [00:03<00:00, 1519.30 uttr/s, accuracy=0.72, loss=1.22]\nTrain: 100% 2000/2000 [00:47<00:00, 42.05 step/s, accuracy=0.97, loss=0.29, step=64000]\nValid: 100% 5664/5667 [00:03<00:00, 1540.67 uttr/s, accuracy=0.72, loss=1.25]\nTrain: 100% 2000/2000 [00:46<00:00, 43.45 step/s, accuracy=0.84, loss=0.53, step=66000]\nValid: 100% 5664/5667 [00:04<00:00, 1352.29 uttr/s, accuracy=0.72, loss=1.25]\nTrain: 100% 2000/2000 [00:45<00:00, 44.01 step/s, accuracy=0.81, loss=0.68, step=68000]\nValid: 100% 5664/5667 [00:03<00:00, 1493.58 uttr/s, accuracy=0.74, loss=1.16]\nTrain: 100% 2000/2000 [00:46<00:00, 42.62 step/s, accuracy=0.78, loss=0.88, step=7e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1440.94 uttr/s, accuracy=0.74, loss=1.14]\nTrain:   0% 10/2000 [00:00<00:56, 35.30 step/s, accuracy=0.84, loss=0.45, step=7e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 70000, best model saved. (accuracy=0.7413)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:46<00:00, 42.65 step/s, accuracy=0.94, loss=0.29, step=72000]\nValid: 100% 5664/5667 [00:03<00:00, 1514.94 uttr/s, accuracy=0.74, loss=1.16]\nTrain: 100% 2000/2000 [00:46<00:00, 43.01 step/s, accuracy=0.84, loss=0.48, step=74000]\nValid: 100% 5664/5667 [00:04<00:00, 1412.40 uttr/s, accuracy=0.74, loss=1.15]\nTrain: 100% 2000/2000 [00:45<00:00, 44.06 step/s, accuracy=0.88, loss=0.69, step=76000]\nValid: 100% 5664/5667 [00:03<00:00, 1518.97 uttr/s, accuracy=0.74, loss=1.18]\nTrain: 100% 2000/2000 [00:45<00:00, 43.67 step/s, accuracy=0.75, loss=0.85, step=78000]\nValid: 100% 5664/5667 [00:03<00:00, 1516.99 uttr/s, accuracy=0.75, loss=1.11]\nTrain: 100% 2000/2000 [00:58<00:00, 34.27 step/s, accuracy=0.84, loss=0.99, step=8e+4] \nValid: 100% 5664/5667 [00:05<00:00, 1000.61 uttr/s, accuracy=0.75, loss=1.11]\nTrain:   1% 11/2000 [00:00<00:55, 36.07 step/s, accuracy=0.88, loss=0.41, step=8e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 80000, best model saved. (accuracy=0.7528)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:52<00:00, 37.90 step/s, accuracy=0.81, loss=1.26, step=82000]\nValid: 100% 5664/5667 [00:03<00:00, 1539.93 uttr/s, accuracy=0.76, loss=1.13]\nTrain: 100% 2000/2000 [00:56<00:00, 35.50 step/s, accuracy=0.91, loss=0.32, step=84000]\nValid: 100% 5664/5667 [00:03<00:00, 1499.31 uttr/s, accuracy=0.75, loss=1.12]\nTrain: 100% 2000/2000 [00:51<00:00, 38.67 step/s, accuracy=0.84, loss=0.90, step=86000]\nValid: 100% 5664/5667 [00:04<00:00, 1277.14 uttr/s, accuracy=0.76, loss=1.07]\nTrain: 100% 2000/2000 [00:44<00:00, 44.46 step/s, accuracy=0.75, loss=0.92, step=88000]\nValid: 100% 5664/5667 [00:03<00:00, 1461.63 uttr/s, accuracy=0.76, loss=1.06]\nTrain: 100% 2000/2000 [00:45<00:00, 44.44 step/s, accuracy=0.91, loss=0.34, step=9e+4] \nValid: 100% 5664/5667 [00:03<00:00, 1461.15 uttr/s, accuracy=0.77, loss=1.02]\nTrain:   1% 11/2000 [00:00<01:01, 32.49 step/s, accuracy=0.91, loss=0.32, step=9e+4]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 90000, best model saved. (accuracy=0.7724)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:44<00:00, 44.57 step/s, accuracy=0.84, loss=0.63, step=92000]\nValid: 100% 5664/5667 [00:03<00:00, 1496.90 uttr/s, accuracy=0.76, loss=1.06]\nTrain: 100% 2000/2000 [00:45<00:00, 43.97 step/s, accuracy=0.78, loss=0.76, step=94000]\nValid: 100% 5664/5667 [00:03<00:00, 1519.73 uttr/s, accuracy=0.77, loss=1.09]\nTrain: 100% 2000/2000 [00:45<00:00, 43.84 step/s, accuracy=0.94, loss=0.22, step=96000]\nValid: 100% 5664/5667 [00:03<00:00, 1501.65 uttr/s, accuracy=0.77, loss=1.06]\nTrain: 100% 2000/2000 [00:46<00:00, 42.98 step/s, accuracy=0.81, loss=0.53, step=98000]\nValid: 100% 5664/5667 [00:03<00:00, 1522.20 uttr/s, accuracy=0.77, loss=1.03]\nTrain: 100% 2000/2000 [00:45<00:00, 44.38 step/s, accuracy=0.97, loss=0.19, step=1e+5] \nValid: 100% 5664/5667 [00:03<00:00, 1535.68 uttr/s, accuracy=0.79, loss=1.00]\nTrain:   0% 10/2000 [00:00<00:54, 36.67 step/s, accuracy=0.91, loss=0.33, step=1e+5]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 100000, best model saved. (accuracy=0.7860)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:46<00:00, 43.29 step/s, accuracy=0.97, loss=0.20, step=102000]\nValid: 100% 5664/5667 [00:03<00:00, 1540.91 uttr/s, accuracy=0.78, loss=1.02]\nTrain: 100% 2000/2000 [00:46<00:00, 43.07 step/s, accuracy=0.97, loss=0.17, step=104000]\nValid: 100% 5664/5667 [00:04<00:00, 1371.30 uttr/s, accuracy=0.79, loss=0.97]\nTrain: 100% 2000/2000 [00:47<00:00, 41.69 step/s, accuracy=0.91, loss=0.51, step=106000]\nValid: 100% 5664/5667 [00:04<00:00, 1330.39 uttr/s, accuracy=0.78, loss=1.00]\nTrain: 100% 2000/2000 [00:46<00:00, 42.90 step/s, accuracy=0.88, loss=0.38, step=108000]\nValid: 100% 5664/5667 [00:03<00:00, 1608.51 uttr/s, accuracy=0.78, loss=0.99]\nTrain: 100% 2000/2000 [00:45<00:00, 43.88 step/s, accuracy=0.94, loss=0.21, step=110000]\nValid: 100% 5664/5667 [00:03<00:00, 1497.27 uttr/s, accuracy=0.79, loss=0.96]\nTrain:   1% 11/2000 [00:00<00:53, 37.01 step/s, accuracy=0.84, loss=0.38, step=110011]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 110000, best model saved. (accuracy=0.7885)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:46<00:00, 43.26 step/s, accuracy=0.94, loss=0.12, step=112000]\nValid: 100% 5664/5667 [00:03<00:00, 1441.30 uttr/s, accuracy=0.79, loss=0.94]\nTrain: 100% 2000/2000 [00:45<00:00, 43.87 step/s, accuracy=0.88, loss=0.68, step=114000]\nValid: 100% 5664/5667 [00:04<00:00, 1347.55 uttr/s, accuracy=0.79, loss=0.95]\nTrain: 100% 2000/2000 [00:47<00:00, 42.25 step/s, accuracy=0.94, loss=0.32, step=116000]\nValid: 100% 5664/5667 [00:03<00:00, 1485.78 uttr/s, accuracy=0.80, loss=0.95]\nTrain: 100% 2000/2000 [00:46<00:00, 43.15 step/s, accuracy=0.97, loss=0.17, step=118000]\nValid: 100% 5664/5667 [00:03<00:00, 1539.74 uttr/s, accuracy=0.79, loss=0.96]\nTrain: 100% 2000/2000 [00:45<00:00, 43.56 step/s, accuracy=0.91, loss=0.49, step=120000]\nValid: 100% 5664/5667 [00:03<00:00, 1545.77 uttr/s, accuracy=0.79, loss=0.95]\nTrain:   1% 11/2000 [00:00<00:54, 36.67 step/s, accuracy=0.97, loss=0.15, step=120011]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 120000, best model saved. (accuracy=0.7957)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:46<00:00, 42.83 step/s, accuracy=0.81, loss=0.51, step=122000]\nValid: 100% 5664/5667 [00:03<00:00, 1510.32 uttr/s, accuracy=0.80, loss=0.95]\nTrain: 100% 2000/2000 [00:45<00:00, 43.96 step/s, accuracy=0.91, loss=0.37, step=124000]\nValid: 100% 5664/5667 [00:03<00:00, 1479.12 uttr/s, accuracy=0.80, loss=0.96]\nTrain: 100% 2000/2000 [00:45<00:00, 43.67 step/s, accuracy=0.94, loss=0.24, step=126000]\nValid: 100% 5664/5667 [00:03<00:00, 1512.66 uttr/s, accuracy=0.80, loss=0.91]\nTrain: 100% 2000/2000 [00:45<00:00, 43.92 step/s, accuracy=0.97, loss=0.09, step=128000]\nValid: 100% 5664/5667 [00:04<00:00, 1333.76 uttr/s, accuracy=0.80, loss=0.92]\nTrain: 100% 2000/2000 [00:45<00:00, 43.78 step/s, accuracy=0.97, loss=0.20, step=130000]\nValid: 100% 5664/5667 [00:03<00:00, 1477.58 uttr/s, accuracy=0.79, loss=0.94]\nTrain:   1% 11/2000 [00:00<00:54, 36.70 step/s, accuracy=0.94, loss=0.34, step=130011]",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 130000, best model saved. (accuracy=0.8012)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "Train: 100% 2000/2000 [00:46<00:00, 43.14 step/s, accuracy=0.97, loss=0.21, step=132000]\nValid: 100% 5664/5667 [00:03<00:00, 1502.98 uttr/s, accuracy=0.80, loss=0.93]\nTrain: 100% 2000/2000 [00:47<00:00, 41.67 step/s, accuracy=0.94, loss=0.19, step=134000]\nValid: 100% 5664/5667 [00:03<00:00, 1453.56 uttr/s, accuracy=0.80, loss=0.92]\nTrain: 100% 2000/2000 [00:48<00:00, 41.55 step/s, accuracy=0.91, loss=0.19, step=136000]\nValid: 100% 5664/5667 [00:03<00:00, 1450.43 uttr/s, accuracy=0.81, loss=0.91]\nTrain: 100% 2000/2000 [00:46<00:00, 43.23 step/s, accuracy=0.94, loss=0.28, step=138000]\nValid: 100% 5664/5667 [00:04<00:00, 1372.70 uttr/s, accuracy=0.80, loss=0.93]\nTrain: 100% 2000/2000 [00:45<00:00, 43.59 step/s, accuracy=0.94, loss=0.21, step=140000]\nValid: 100% 5664/5667 [00:03<00:00, 1422.07 uttr/s, accuracy=0.80, loss=0.94]\nTrain:   0% 0/2000 [00:00<?, ? step/s]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Step 140000, best model saved. (accuracy=0.8060)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference\n",
        "\n",
        "## Dataset of inference"
      ],
      "metadata": {
        "id": "NLatBYAhNNMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InferenceDataset(Dataset):\n",
        "\tdef __init__(self, data_dir):\n",
        "\t\ttestdata_path = Path(data_dir) / \"testdata.json\"\n",
        "\t\tmetadata = json.load(testdata_path.open())\n",
        "\t\tself.data_dir = data_dir\n",
        "\t\tself.data = metadata[\"utterances\"]\n",
        "\n",
        "\tdef __len__(self):\n",
        "\t\treturn len(self.data)\n",
        "\n",
        "\tdef __getitem__(self, index):\n",
        "\t\tutterance = self.data[index]\n",
        "\t\tfeat_path = utterance[\"feature_path\"]\n",
        "\t\tmel = torch.load(os.path.join(self.data_dir, feat_path))\n",
        "\n",
        "\t\treturn feat_path, mel\n",
        "\n",
        "\n",
        "def inference_collate_batch(batch):\n",
        "\t\"\"\"Collate a batch of data.\"\"\"\n",
        "\tfeat_paths, mels = zip(*batch)\n",
        "\n",
        "\treturn feat_paths, torch.stack(mels)"
      ],
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "efS4pCmAJXJH",
        "execution": {
          "iopub.status.busy": "2023-07-15T08:11:37.406063Z",
          "iopub.execute_input": "2023-07-15T08:11:37.406481Z",
          "iopub.status.idle": "2023-07-15T08:11:37.417414Z",
          "shell.execute_reply.started": "2023-07-15T08:11:37.406442Z",
          "shell.execute_reply": "2023-07-15T08:11:37.416331Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main funcrion of Inference"
      ],
      "metadata": {
        "id": "tl0WnYwxNK_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import csv\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "def parse_args():\n",
        "\t\"\"\"arguments\"\"\"\n",
        "\tconfig = {\n",
        "\t\t\"data_dir\": \"/kaggle/input/ml2022spring-hw4/Dataset\",\n",
        "\t\t\"model_path\": \"/kaggle/working/model.ckpt\",\n",
        "\t\t\"output_path\": \"/kaggle/working/output.csv\",\n",
        "\t}\n",
        "\n",
        "\treturn config\n",
        "\n",
        "\n",
        "def main(\n",
        "\tdata_dir,\n",
        "\tmodel_path,\n",
        "\toutput_path,\n",
        "):\n",
        "\t\"\"\"Main function.\"\"\"\n",
        "\tdevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\tprint(f\"[Info]: Use {device} now!\")\n",
        "\n",
        "\tmapping_path = Path(data_dir) / \"mapping.json\"\n",
        "\tmapping = json.load(mapping_path.open())\n",
        "\n",
        "\tdataset = InferenceDataset(data_dir)\n",
        "\tdataloader = DataLoader(\n",
        "\t\tdataset,\n",
        "\t\tbatch_size=1,\n",
        "\t\tshuffle=False,\n",
        "\t\tdrop_last=False,\n",
        "\t\tnum_workers=8,\n",
        "\t\tcollate_fn=inference_collate_batch,\n",
        "\t)\n",
        "\tprint(f\"[Info]: Finish loading data!\",flush = True)\n",
        "\n",
        "\tspeaker_num = len(mapping[\"id2speaker\"])\n",
        "\tmodel = Classifier(n_spks=speaker_num).to(device)\n",
        "\tmodel.load_state_dict(torch.load(model_path))\n",
        "\tmodel.eval()\n",
        "\tprint(f\"[Info]: Finish creating model!\",flush = True)\n",
        "\n",
        "\tresults = [[\"Id\", \"Category\"]]\n",
        "\tfor feat_paths, mels in tqdm(dataloader):\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\tmels = mels.to(device)\n",
        "\t\t\touts = model(mels)\n",
        "\t\t\tpreds = outs.argmax(1).cpu().numpy()\n",
        "\t\t\tfor feat_path, pred in zip(feat_paths, preds):\n",
        "\t\t\t\tresults.append([feat_path, mapping[\"id2speaker\"][str(pred)]])\n",
        "\n",
        "\twith open(output_path, 'w', newline='') as csvfile:\n",
        "\t\twriter = csv.writer(csvfile)\n",
        "\t\twriter.writerows(results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(**parse_args())"
      ],
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "95bd670c259f45acab0f0eee2378d328"
          ]
        },
        "id": "i8SAbuXEJb2A",
        "execution": {
          "iopub.status.busy": "2023-07-15T08:11:37.422096Z",
          "iopub.execute_input": "2023-07-15T08:11:37.422447Z",
          "iopub.status.idle": "2023-07-15T08:12:03.505110Z",
          "shell.execute_reply.started": "2023-07-15T08:11:37.422415Z",
          "shell.execute_reply": "2023-07-15T08:12:03.503989Z"
        },
        "trusted": true,
        "outputId": "54728b4b-d953-4f70-aa07-0cc6ab319c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "[Info]: Use cuda now!\n[Info]: Finish loading data!\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:561: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n  warnings.warn(_create_warning_msg(\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "[Info]: Finish creating model!\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/8000 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "95bd670c259f45acab0f0eee2378d328"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# \n",
        "\n",
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABkMAAAB8CAYAAADaU8dIAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAAAJcEhZcwAAFiUAABYlAUlSJPAAAFpDSURBVHhe7d0HeBTVGgbgL733QkjovYbee+8oRbqC4kXsFUVERUVQsKIgRboiCtJRegKh11BDSEgI6b1nU+HOP7sbUiFRUIjf692bndkzZ8605Xn+f885BrcVICIiIiIiIiIiIiIiqqAMdX+JiIiIiIiIiIiIiIgqJCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNCZDiIiIiIiIiIiIiIioQmMyhIiIiIiIiIiIiIiIKjQmQ4iIiIiIiIiIiIiIqEJjMoSIiIiIiIiIiIiIiCo0JkOIiIiIiIiIiIiIiKhCYzKEiIiIiIiIiIiIiIgqNIPbCt17egTJ5ZNXTk6O+tfU1BSGhv9ejuthaw8REREREREREREREZMhjzhJOoRdPoJd23fgZGRlvPLBs2jmavOvJSAetvYQERERERERERERETFC/Qi7desWUsJP44s3/od5K7fCOyQSt/LydJ/+8x629hARERERERERERERCSZD/gH6oaPudyccAwMDNQGRe0u3ooz1yzYPU3tKI3XpX/eiP56yliciIiIiIiIiIiKi/44HlgyRgHRubq46bFLBl6yr6MFqCcrLcWZkZCA5IQYBF87izIUAxCYkq+vks4KJCDkfmZmZSE9PV/8WTVLIspw72VZe2dnZ6kvKZ2gycUtfXCmnkXVKGY1Go24jf2U5KytLfaWmpiLC/yLOnL2EmPgktQ4p96DbI/Xc67pLvVJG2pycnIzwqxdw5tRZXAuKVNst+yjYFn15qT85IRaBF8/hyNHTuHo1CDHKuZZ65HN5ybb69hY9XqE/Jv35kvL3ai8RERERERERERERPRru25whEjiWYLK8snNzEJUUgwsRVxGXkZgfeJaeA86WDvB0bwA3e1eYGpvAxET7qihzSsixStLBz+dXLF+yEvvPhiNT9xlgjCqe3TF+yrOY2KMRzM3N1fIp0RewePYXOB6eAYe6fTB9+pOo52ilni8hyZPLO7/H1z/5IBl26DThJfTI9cKCX44iXjm/N66GIl0taYvaDTxgZWIEq2od8ORjHti1cjNCNOao32MIGmpOYuPv23A5Vi2sqtS4GyY99zwm9nrA7aneEdNmTCl1/hDZr9R788p+rP5+CXYdvITYXN2HwrYhxkyejBfHd4e7vY3aFrnXoq8dwMLPv8LvR4JRsDhgjgY9RuDVV59Fl9qWOLRiDlZ4BSHX0BKtx76It4e2Vu87Panr8l7lmFYcRvItI3h0GItZLwxQ7lez/OMmIiIiIiIiIiIiokfT30qG6APYEvy/GhGItee34kDUKSTnpuFelRrCAO6mzuji1hKjmg5AA/c6MDMzg7Gx8SMbfJbzIefi5O9zMeujdQguHJ0vwA0j3/sY741rD1vlmGODvDBj0lQciFA+avgYNix5Fy3dHfKTBlLn4eUv49UvvJAOK/R8ez7G5P2GV770LpBoKaJ6X3w0xQOr3luJYN2q0lXB+FkfYuao9jA1NX1A7emH5cs/RI+aziVeX0lGBJ/ZhDlvz8TBMN3KEtQe8gaWvDcWVe0tcf3IGsx4/XP4pug+LIGF5zD8+OVrMD77PV59ZwOilHW2nSZj05fPo5aLrdoWuW6pScFY/fZEfLVfStjh8fe/xLwJHQslTIiIiIiIiIiIiIjo0fSXumNI8FiC14nJSVh28Bd0X/UUhu98HZvCvJBUhkSIuKWUCsuOxS83d6vbSh1Sl9Qpdf+NHM2/RhJDwcd+woL5+kSIHdoOGY+3P5iNzz56F08OaQYrtWQUNn75FdZ4+6nbiPzDVd6UlCwodDaUMvaV6qNtS080blBVV6eQnhgN4dm0Cdo3qQ5rY8Mi18IOLZT2zPzoU3z24VuYMFDfnjD8/O0P+M33JvJ0E57f7/Z0aFodDpamStHCLRKyLinSFyvnfZqfCHH07Iupb7+HubOmK+etNZy1q3F9+xJ8sfEYEpIjsf+31fmJEOOqLTHi6Zfw0QfTMWXMIDRz167XXNiOH7acg2Pj3mhVQ7su5fxxHAmKzh8GS/afEnoWR85JIkRRuQV6dqgHIyMj7TIRERERERERERERPdLKnQyRwHFaehp+Ob4VPddOwtyLKxCdk4DbRcLu5SHbSh1Sl9Qpdcs+HrWESEbqTfzx0484owbojdHmmXfw3cev49nxwzFs9AS8+eEizHq+G+zl48yrWL5mN64lppf/3BkYoGH/qVi4ajUWzn8PHarq1tfvhlnfLMTPP6/FsrkvoK5dwV4NVug+dToWK+15aswwDBv7NN6cvQjvP9sOZvJx4lms+d0HsemZD6Q9K+a9XOoQWeoQVfvWYJevRl22bTcBC79+H689PRYjxj6Ftz9dhgWfT4Q2l5GOfXt84B8dgtAIXfLCohGmffgOPnztGYwZ9yRenTkHcz5/H61t5MNcnDh6FinWddC2U0O1ONL8sffwNaTpkm6y/6vHvHApQftx7Q7t0LqydiguIiIiIiIiIiIiInr0lTkZog8aB4QFYdz6NzDz9ELE5ybrPr1/pE6pW/Yh+3qUeomk3DiBY6fitQvVuuPZUZ3gbGOjDrUkw0/ZOrigx4RXMbytrVok5dwRHAuIVo5PXSwzCdJLnVZWVrC0MIehPmavrLeQdZaW6vwfhYL51dpj7OMdC7fH1hkdB41CG1dtkeunTiMwLkO7UA5lbU9pc4Vkpofh5MGjSFLXVMcT4x9DqypO6rBpUq9s36DrMPRprz1vuSGhCEsxh7O9dhmaa9i0fgu8T19FUppG7dFRrUkfPPnaS5jyzFOY2rcR7C3s0bJ7XzQ0lg0kQXIMIZKIUvavSQ7Dce/junlOqqNHz7acK4SIiIiIiIiIiIioAilTMkQCxtnZ2dh74RBGbXkDvqkBpfYesDOyQj+X9pjX9jXsf2I5Lj6zBVee3a6+5L2sk8+kjJQtidQt+5B9yT5l349CQiTi6iWEpGnf127dEk3dtXNS6Ml7K4dq8GzbGGpMPjsS5/wj84drepDcGjZC00rF22NbtTHq19QlFSJDcS06qdzJmb8rKzEE14N0411Vr4OuDSqrc8foSRLF1rkBnpqxGCsWL8Lyb19B97oN0G3wEGg7oeTCf98veGXyOLQb8Bzmr9kO32tJaPvYk3jp1dfw4qTBqOZgCffG3dG6uYW6Rc6ls/D2i1KTbTFBB3Hygnb/xo3aoG9Tdw6RRURERERERERERFSB3DMZIkkImTB7/YlteN1nXom9QWQy9HZ2jbGu7+c4Mmkdvh85C0+0G4w67jVhb2cPGxsb9SXvZZ18JmWkrGwj20odRcm+ZJ+yb2nDw54QSUuKg3agJzNU9qgMRxOTQskHYWhoAVtHZ1irSxmIT0xH5j+QDHFwsIeFafEAv5GRJZyd7bQLOWmITv5nz7PsKyc9EcnabhkwtnWAg7VJsTZIcsKjcWt07dUT3Tq1RGUnazQd/BrmfP4SOtVVx8PSij2D5XPfxZOjh6Ln2Fcxf8UO+MemqQkVS/s66Nq9vXZOk9xAeB2+goTkBPj5eMNPvXDGaNetI+q5WJfYi4WIiIiIiIiIiIiIHk13jfhKQFp6Zaw59js+ObsUGbezdJ9oGSj/eVrXxsaBX2PNmPno1LANbG1s1SGR5Jf9JQWUZZ18JmWkrGwj20odUpfUWZDsU/YtbXjYe4gYmaizbyjykJVzC5kltFXafysrGzm6ZVNj7fEWTwUV9nePWzlzpdehnTNdYQwzE+01e9DtKcjAxBS63SI37zaySqhbes9IQiwjIwMajUbt0WFgYI7mAyZjwS9/YN23MzCiT2vUUidk0dIEHMfabz/A1I/XIjgpVR1yq0HnvmjiqP3c94gPzgRewtGjp6BOY2/dFH271Ie1Uo6IiIiIiIiIiIiIKo67JkNyc3Ox03c/vjy/Blm39eF7LTMDE7zWcBx+GfM1WtX1VOd1kERH0Z4QdyNl1V/sK9tKHVKX1Cl1FyT7ljZIW6RNDytrZ2do+yjkIjT4BtIzC893Iu9zctIQGhSgm5/CDi4uTrA0NoaR/krk5SAvLz87oW6Tm5uO8PAo3TZ/TWxYNBKU9hQkdWdr4hEcHqldYe0IN0dbpS2GD7Q9UkfBocFMrBxh56BbiItERGKmbkFLymekRmPd24Pg2awlmrYcg0U7d2LFwu/x3XcLseN0BJr3HoNPvlmBTV5HsGX513hhZCc467aPPLQPu67K3Cy3YV+9Ezq3083wHnAeO7Zvx5nL2nvKuXU7dKpXib1CiIiIiIiIiIiIiCqYUqO+Eqy+EHIFs08uKdYjxN7IGt92fgcvdH8SNtY29yV4LHVIXVLnt13eUfdRkLRh9smluHjT7x+ZY+OvcG/QCo0qa99HnTiOg9di1eSNBOGFJBUSbxyBz+EgdRkOtdGufmUYm9nBWjdtBxKTEJmSmX+Msm1K6FkcO3pVXRYFU0X6uvVKOzcpvqfg4xeR3x55yfvwS164cFWXYKpaDfVdLWFoavtA2iOfSe+e5KgwBARHqT08hLltTTSo56a+R4w/Dp+5UWjifPmbFhuIs5duqstwr4pa5vHwXrMES5f9iC/X7kF4eqY64bqtrQsad+mPSW98gIn9q2jLZychJiZVfWtm6Yy2PbtCu7cI7P71T1xXD98JPXt1RFVri3Il9IiIiIiIiIiIiIjo4VdiFkOCz0kpSZh/eDlii8wR4mxsh0W93kffZt3U4PP9DBxLXVJnX89u6j5kXwXF5iZhns+PatuKBt0fBtLroP+QVtrJ0ZNOYe7cxdhzMRxpaWlITU1F5FUfLPlqCQ7pOmI06j8AvRs4wdzWAw3r6HorxJ3CilXb4B8Rp26TEBuC/RtW4aAuD1CQnAMjMwtY6eehT47DjfAYdbvMzMzC5yjNF99/tVJpT7D6ubyCTu/AsoVrcVXtMGKFXv17oa6zFSzsqjyQ9sgwV6c2fYExvXqif59uGDJtGYLjUtUERY/HR6OueuLisWHNT9h+OkjdTs5dYtxNHNqwFPtuqLWiUaeOaNaoJWrX1qZhUo7uw7pDV5GSkoL09HR1m5sXj+LM5TD1cxjbwMXOUvvW2Bg12/RBq9rq4h3VWqBPu1rqUFpEREREREREREREVLEY3C4hqyC/yv/52GbMOrMYebjzy35LAzN81uE1DG7ZWw0qP6hf0EuTpNfCjrP7MP3YN4V6phjBEB+2mooJHYY9dIFr6QURG3QEc16dgm1++uG87FC7QSXcTolBUESSbp2iSg98u/BDDG5cWe0xcnHPl3jr5eUI1n0MWMO9tjussyNwLTRNt05Yof87X+CbSV1gamqKtOQbWDptLL7fH6/7XKv6YzPwSc9YfPDqMuhyCPkcqtaFq0Umwq6F3hnqqt4grP7+XXSu5fKA2vMeVrzVHls/nIQFB3SfObTDF6vn4/GGruowWL9+/DQ+3aLrNQNjuNZR2mlugOyEIFyL0A2dVakzPl/8MYbUc8bJTR9j+vsbEaX9RGGNytXskRMZhrgCI4LZtnkSP337Ehq72qv3rEaThB1f/A/vrDqvKwE0GvshfnpvOOwt2DOEiIiIiIiIiIiIqKIxmqXQvVdJQD8kJgwzD36DpLw7s0IYKv+91GgMxrZ7TA163++AsSRA5CXDKBkZGanDZtV0rgqk5+FE7CWZ/ltbTvkvMP4GelVrD3sr24cqcC1tMbNxR926lRB1/hCCEiSRlIXEuHgkphaYB6NKe3z40dsY3rJq/rHaeTRGVZsE+J3wQ6Kaf8pGamI84lOyAZem6Oppg5CwRGW9Gep2HYABzatpJ6k3soaDVQ7O7zuB2ALTqdjV64geNTPgvessJAVj3bA1mlrGIDL5FjJTEhAfn5I/iTvclfa8/zoGenrkT3x/v9tjX68ThvfwRFrgYXj5RqspNpM67fDsyG6obGMBUzNrVKvXELnXD8M3VO67W0hPiENMTCziU3UVKe18Z9YrGNumlnoPutRoCXezm7hw4jq06ZlspCWnIONO/k7dZsb7L6JnXTf1XMs1MjAwgYlJOs7tPIxYmQ7FsC5GvzwRXWu7qmWIiIiIiIiIiP4uibHJD45lpAwZMUPe6+fCldhLWWJaUodsU9aXlC9ad1nbIXE5+YGs/vN7vfRzzGpjLQ9PfI6orOTZ0D8X8lfufbmv9ff0ve5rfTxbtivLcyN1S/mS6pb1+nLyvuhzLOukvRI717dX3uufw7J+p/zXFesZIidxwYFVWOD3S34CQjS3qYuVw+fCycHpvp9Y/cU+4n8KP13chve6PY/qblXV/cQnxuPpTe/CNzVAV1pptPLfq43G4uUek9Sg+MNEjkVuwvSUKJw5sANb/zyIGwnaRIi5bQ107dcPQ/q2g7u9TX5wXsh2cu4Tb/jC2+swjvv6ISXPFnXadsHj/TsCIcexy+cS0g2s0bzXYxjUqpp6k8t28rBF+B/DXq9TCE/KUOo0RbWmPdDEzAdvv7hE7RlSdfAbWPRCO5zbug5/nAhChrKdqbkLWvQcinGDO8DD2bZQb5/73Z4azXpjeH9P3EoKhffW7fBPNkP7AYPQsb67ul8hD3RGRiIuH9uNbVv24GpEMuSfZjNrVzRq3w9jh3VFLRe7/HbKvuTBj/A7hp27vBF4IwwxcQnIgDGcKtVCoxat0KdfDzSqbF/s2KQnyv7ff8W58BRYu3pixOheqG5rlV+GiIiIiIiIiOivkthQUsx1eP3+C7bu98HlyyFINHZGvSbN0X3AEDz5WCc1NiSxlNJI/CI9IQBb1u9EYHyqunxXBoCNXVX0GjECzdy1dZenHRKbCzi0GVtO+CMzJ09pgK7eUhgamqnxnhEDmsGaw47TI0SeJbnfwwNPY+eGddjvcwZ+12OR61gFLZu3Rr8RIzGsW1PYmZvf9RmVWGZCwEH8uv0YYjJy7vnMSNzRzr2FGocsOG+xtCctORJHt23D2dBkONRojXHDOsPGQtshQZ8ECTx7ANs2bcahE2fgH54KY3s31KpZH32Hj8XEQW3hZGfN2OY9FEqGyNvoxBhM+G0a/DV3JoWwNDDFdz3eQ8/GnfID1/eL/ubz8TuB1w/OQ0JuCprZ1MWCAe+hRuVq6sU+cOkwXvaeg4zb2bqtgPoW1fDTqPmo5OD6UF5k/XHJS45ByMMj569gYL4oKavfRurQl5dlfaZPv72+Dimn35/81a8LOLQQr0xdrCZDqg2dhl9mjYWT8hBJPfK5bC9Djel7p5TkfrVH9iEvWdbvX7Yrul/957Ktvn4pI9uWVl5e+vLSLqE/16Udm34bKa+vv6RyRERERERERETlIfGJmKAj+Prd17HhbIpubWHVek3Bdx88jSYejqXGIyR2EX3tD7wx7jUck8E5ysK0IWau+BKT2tVSF8vTjuzsVOz84lm8tcJX9+m9VR86Hes/HoNKNpb5cSGih5k+Jhh4eDU+mfE5jkXrPijEDj2em4bZzw1E5bskGKQev11z8Nwra6GbIvre6g7Gz8tnor27g1qv1JGaFIGtP8zEV6uOq6PfmLSdjD8XPY9aDrbqJukpCdizbDo+W+SNWHVNcbUHvIivZj6Jpm6OfBbvotC3rXxZHwk8g+DMCN0ardYOjdGxTis1YHw/6W++gokQcT41AC//ORthcRHqPwgd67ZW21CQtFHaqg+YP2zkppNEg4WFTChupb7kvay72w0pxyu9XczNzQuVl3Mv6+UlZQrWIe/128kE9PLSJygKkmUpY2lpqbZH/kr9pf2jK+53e2S91KHfrigpI2VlfwXP293K6/dV0rkuaRsh28nn0rZ7nQMiIiIiIiIiorKQH12mxt/AunnvFU5A2FeCm7XuveLm/qWY/v1WRKWkq/Gx0hgZGcKoPHFNUyOYmZirdZa3HcLIsDw7A0xMTWFgXL5tiP5N8mzEBnpjwSeFEyHWbm6w170HkuG15DvM23RGHZXmbs+osfKMlusJMLWQx1SNaackhsNn61p88vpEfKxLhKhu3Zl7QGLn/odWYfHSO4kQx/rtMWBwP3Rs4qJbA1z/cwk+XemN5MzMu7b3v65QBFhNhoScQfbtOyfc1MAYIxr2gbmZuRpAvl/kopSUCNELTAvFmdDL6nvZ94gGfdS26Ekbpa0PazKEiIiIiIiIiIj+WyTWdXXvj9i4P0q7wqMT3l+6HucO7MAfBw9jzVcvwlP7Y2/4bViPdccC1G1K41izL37wPocL58+W+Dp75iQ2fP8CGuhGqbL1bIsOtWzUeFl522FoaIEBb67FxQsl78/33GkcObgTL/X20G4ID3Tv0giOuh/OEj3sJB6t0cRg30/fYZcMpaNw6jgGP276E4f/3IE9R3fji5f7wFn9JBpbV/6MQ8EJpSYX5MfidXq/g92lPDPyOnniKBa83BNW6hbGaNOpJWrbWSD+2h5Me6IPJr89F1uOhqufFqVNrvpj2+rVCJCvCeMamPTpMhxY/z2+/Hw+Fq3dgkUzhilPosjFyT924fDNZHWJSpafDJGLmpSejIsJgbo1WlVMXdC2ZrP72ivkXokQGZZresvJGNiku/plKvtuW6uZ0hbtrah3ISFAbXNpN+R/nWQm9VfNwIi9H4iIiIiIiIiIHhSJT2UkBWLXjp3QpiCq45k3n8f4Lk1gZ2cHe3tXtO73HF59bbAu2HoDm3YcQ1xGyb8818fErK2tYWNjU+wl601Nb8PviBeu5sgWTujRpwOqWFtAk3y93O2I12SrI2/cbX850adw7KQ2cGvctAP6tqp+X2OGRA+SPGfJQaexd5+fdoVHN7z35rPo2rg6bG1t4eRaA70nzsCUkQ20n4efwm9efur8yCXRjzxT2jMjo9cY5UXjyKFDUPte2TbF4O6esDI2RkpyNKIi9YnQSmjXpyuqF5mdQpKagUc24sBZjbpcbeATmNyvhdpWGRXHxsYZHYY9h8e66DKbEYG4FJTIzgN3USg6HpUSi8jMON2SVl27GnC2uX+Tpt87EWKGd1v9D2PbDlW/gGW/8pI21LOvqSulFaW0NTI5RrdEBck/RFWbD8OnK5dgyeJlmD+5H1ys7m/vHiIiIiIiIiIi0pKYV2rYZVzy0wYu0aAZ+rWspQZL9fEtGa67QceBaKrrXBF5wReXY7VDVJWXGti9eRTe3rrAbo2WGN6pgTr8+P1uh+wrJycNJ/dtx3k1lGeGbr27oqmjNX98S48MSRKEXjyKq7rxpqq1bof2dZ0KDe9vaVMJHfr0QA21RDrOn/ZFhCZbfQbKS/YXfGo7TpzXJj0qt+uMzvXd1LitsSQ63eqi99gXsXTjCrw3vgsczdViWsr+sjLi4HvgEMJk2bgORgzpqMZ3ZTJ1jUaj/jWzdMeAp9/GlP9NxOTnHkdTVz6Td5N/ZqTbTVhCFDILTFIuWrk1um8Z3rIkQt5r9T+MaTNE/VKWm1BP2tCiUiPdklbm7RyEJ0arbafC5NxZOlRD687d0KtXF7RuWJkPAhERERERERHRAyKBz+iwK4jShbtqN6yPqo4WheJb8t7apTaa1nPUroiJxNWwxL8U25Jfq1859CdO6GZubt69B5q62z6wdqRGXMLB/WeghnVdWmFIt6bqD5mJHhV5eRkICboGbVcAO7RoVgdOuh/j60lixKVmM9Stql2OCw1BeEr55+GQ8pnpsTi2ay+0I3JVQu++7VHV2kKN0VZtNgLfbf4N370/Fd2b1oStmUmhuUdke01yEC5cC9WuqNcILavaIfSSFxbMmYFXpr6I12fMwY+/7ECmexe8+OIrmPbaVAxo4VHoeKiwQsmQ0KRIZN2+0+3HzMBE+bJ0vy9B9LIkQt5t9SxGtRlcLBEipA3VlLZIm/SkrdJmJkNKJudQkkjy4kNARERERERERPTgSOwrOTIWSbplRxc3WOp+cV6QibkjHCrppmrOSURYfEq5Y1tSPj0xAPt3e2mH3zFvjEG9PGGjS07c73ZI4iXw2A6cvq5drtahE9pWt2e8iR4Zamw6KwOJkQm6NVZwcXUqFveWcibWleBgrxuzKjYOUcmFOw+UhTxLCYGHcfiYLpnRoD0Gt66R3wvFxNwajrZWMDc3LzV2mxkXiSjdJO+uDja4sPVLPDf2ZSxauw37fHywa8sv+Gr2DDzRfzRmrjiAhMwctR4+l6UrdLWTs1J177QsDExR1c6txGSI3Bgym75km+X93ag3270SIS0nl9gjRE/NmCltsVDKFpScWbjNRERERERERERE/7TbtzORkZGKLHXJDDZWxjAvEuPSByotLW10a7KQlZ6he192Eo8LO7sdx321P2p2atMJPRpqh9+53+2QuJ4mLRQ+u/dAG5etjr5928PZsuQYHtHDSp6N5AzdcHDGFrCzuPOjez25p41MLWBjqfssNwOajPI9o/LMyLByvvs344yalTRG2x5dUb+Sbm4Pnbs9P5JMSUuJQXKmdjnmyM+Y/8NOBEnXLOtKqFrNDdbajxRR2L5gNj5ZdxgpWSXPQURahXqGxKTH65bukCRE0RMoZYMjQvDU+mnYd9FHzQ6XdpJlfZmGxmo7tNREiJB6tEmZwvuJVtpcWtaaiIiIiIiIiIjonyCxq1vZ2dphpGAMM4uS526VdeZmlkoJkYvsLO22ZSVlCw+/44pefbuow+9I3fe7HZJ4ibjsBe/T2pieSfN2GNqyipp4IXqUyP2dk6N9MmBsBDOT0ntRmJhbaN8o5bPybpfrGRUp0Rex78Bp7XNo3xTDezSDtW7enrLK1aRAo2uuyro+Jn7wPY55b8PO7X9g38GteH9iO2j7dyXjz59/x6GAhHK39b+kUJePoufpdqGRyrTUREhkCKbseB9HEy7grUNfYO/FQ2rCo+iJluV7JUJmlDI0VnZ2DpKSUxAVHYuQ0AgEh4TDIs8SmwYvxK7By/Br36/xeYc30dS1/p2bmIiIiIiIiIiI6F8gcS1DU9P85EKWpuR5BmRdZlZGfrLC1OzuvxAvSrZPvH4EXod1w+/UboUhHWqrE6SL+9kOKZOdnYrTu7bBT/2FuhW69u6BuvaWJY4kQ/SwMzHRDX+VlYesnNKTHDkZGu0bpbyZUfmGnpKOA0EnduJ0gHa5cvsu6FLH8S89M3f6rthh6Muv4e1RXVDJwQE2NjZwrdIQw16cg0n9KmmLRJzCn8f91Xg8lSz/CsjFqGTtpFvSMsBtNfmhv9jyPiwuAs/vnAX/DO0XblJeGmYcXaAmPAomRORvWXqEjC4yNFZKShrCwqMQHhGtJkQsLS3gVskZNat7oE7t6qhbuwYa1KqFVnUbY3DjHuhbvyti4xLVbWRbIiIiIiIiIiKif5qBgTmsrGygHeA9CwlpOcgsEmiVeJnE1zJS9cO+S88NS937e9MnJ3wPbNcNvwO06dYFTSrfGTDnfrZDyiWFnIb3IT/tCpdmGNqlISdOp0eSoaEF7CyttAu3NUhWng25xwuS5bxsDVIzdckQY0tYWJbvGVWHldvphSh1jQd6924PF6uSe2jdjbGFLYx1uRs4N0LPjg3UOUb09chfa7vKaNu9C7RR/XQEXA9HRhmmtfivKpSOsjPTjxOopbmdjdDkKPXLUe9s2BWEZGgvpZ4kOt48OB8nAs7lJ0TKkggp2CMkLS1D7QGSmpYOe3tb1KxRBa4uTrC1sYaZ8gVbMHMm3fBknXzm4VZJLSvbyLZSh9RFRERERERERET0T5HYlWvVKnDQLUffCEFGVvGRVHIyExB2M067YO6GOh725frFuAy/s3ffMW2PDusmGNzLs9DwO/ezHfIL96s+W3E2XLtcu2tXtKlmV+6gLtG/Te5ZYzNLuFXT9aJAMoJDYwrFvfUyE28gQh/+rlQZ1e0Lz2F9N/ph5XxO6aajaNRanTi9vMPKybNobesKO3PdCitLOJiVPMyWpbUN9MWyszKhyc7TLVFRhXqGVHGoDDMDfboJyLqdg5sJEfk3hZzsAY27qYkMSWgUFJebjJf3f4rj185Co9GUKxESE5uA+MQkODnaw8O9EqyVi1teso1sK3VIXVInERERERERERHRP0Fia041m6CGq3Y5MsAPAbG6yZp1JCGRGnYZV6/r4mVVq6NBFYf8AKd8XlJwVq/o8DvOrTujU33txOl696MdQtqRlnAN3rsPQe2EYlAb/fq05cTp9MgyNrZClUaeqKIupePy+SuI12QXShRKMiPsymnlmdEuV6vfAFVs7/TGuNszKp+pw8rt3YaL6rByZujcqzvqu9oUSzSWhYWLOyq76RZSU5CYUXJPlrS4OOVotKwtzWFhyvl8SlM4GWJfCeYGhbu5nY26ot4EQi66dIOTRMa7rZ4tMSHyyoE5WHnoN7zm/fk95wjJU26csPBo5ZPbqF7V/S8lQYqSOqQuqVOGzsrVtZ2IiIiIiIiIiOhBkbiZtVtLtG2qi17euIAdxwKRlZWlBizllZmZDN9D2+Gr65DRqHUbNHbWDtsjo6ykJMbC3z8Y8WlpajyuYOBT3svwO4d36YffqYSe/TvlT5yu93faUbAe2X+k7174nNMOF2TRvD36NXXnxOn0yJJ7t2qjLmhcTbscdeo4DgXE5Y90JK+05BAc23MQErEGnNChvaeaABTZ2dlIjgpDQHCU2hlAyhcky+qwcl66YeXsPTGkWzPY/IVh5eRZtHRqiLZtGmpXJFzBNi9fJGfemQNI/qanROH00ZPahCXsUL9BHVgZGxd6lumOQimpynaucDN30S1pBSTfQFxqfP5JlhMpiYwxbYbgrWYTYWZwZxoXIQmRz/xWITFPP+aglr5HiH6OEEmEyLwglpbm6nBYpZH9yo0mN1ia8g+BvOS9fIFLFk7frqKkTplvRPbBhAgRERERERERET1IEjMzt3JBj1HDUFcdeCUGG5Yuw7rDl5GcnIykpBic2bMay3701v6K27YlRg9pmx8ovem7BW890QkDB/VHl3Efwut6XKG4l5qcuOKNQ8d1w+/Ubokhre9MnK73d9qhD6DKfrMy4nB0zw7cUNdYoVvfzqjvaP2XfuFO9LCw9WiKwY93V+5oRdIpfPHtchy6HIKUlBTERQfjwNqv8NPeMLWsiWcvjOhSW02iSK+sU5u+wJhePdG/TzcMmbYMQbEphZ7RosPKVevQCV1qF+5xVWbKNqamNmg3ZBRa2cqKdBxYvgSLt51ETFISUlNTERfhj20rvsCGvdrUDWq0w8AONWGcP9EIFZX/7SUXxd7KDk0d6ujWaIVlx+Jk0Pn83iFCykpC48kOwzHNs3hCpKiShsaKioqFjbUVHB3sdKXukJtIMnKS+Ii+4YvtS77CtHfewdRxg9BvwHg8/9Y0TJ/3PbxOBKk3qiRLSkqKSN2yj6goXZqbiIiIiIiIiIjoAZEgZI0OE/HsU620Y/iHH8EnU8agRc/BGNitM556YyEuqAOp2KH/lEkY2qyqGmiVOJj/0R3wDpbPAM2lEzjsF5Y/HI/EvWT4nVN7/tANv2OMNr26oql74fl/9f5qO/Rkf4k3DuOAT6h2RaXmGNi1UbHEC9GjRBvTtkWH0a9gXCftj/Pjj/6KZ4cPQOcBg9G3Yz+89d1eqJFk66Z46cVxaO6mnSMnWxOBk/u2wV99/oDrx07CNyYjPyYtz2p6YgAO7tENKwcP9OnX7m8NKyfPZBXPQXh6Ul/Yy4q0q1g6439o320IBg0ZiJ5dhmDW4j+hzb1UwYSpT6Frtb+YfPmPKJTKlRPcqXpLmBaYNyT7di5+v7oXmVl3uuAI7c1jhokdR941IVLaHCGmpiYlJkLUGyc9HRf2rsDLY7qiS69ReOvr5di5408cuRSBiPArOPjnbmxZuRjPjh+A1t3G4a1FW3AzLjG/S1NBsg9TU2POIUJERERERERERA+UxL2srBzR9/lPMW1sy/xJjZEUjag03Xs4o9/L72H2+C6wM9fORSAvV4+aqKwrAZtKqOZqV6gXRlr4ORzzvqBdsPHE4O6FJ04v6K+2Qy83Nx2XD/2B87pwWp0unDidKga5h+1dG+GZD+djfHtH3VogLSpKl8RQKM/X87PfxZQutfN7WRibOaBajarQR81NPDxQw+HOFBIS046+vA+Hz2qHlTNp3An9WpR94nRDQwMo/9MtaPcibTU3t0PXSR/hg1f63Pl+SItG6M0o5D/KTp54ZvbHeHOIJxOW92Bwu0D2QN5GJ8Zg/G9v4ZpGl/lVSELjux4z0FO5iEW72cg2MmTV8sO/4suLa5GDXN0nJSdC0tIy1AnOtfN6FCY3TUJsANbMfB4/7A+9U5OFM5q1bA4POwc4OGUgIS4FN0+fwuVYXSpOYezeBZ8s+ADDm7irF73ol3NIaAScHOxhbf335yUhIiIiIiIiIiIqjcTLMjMzEXzxIPbu84a/fwRSjGxRs1FT9OjVBx0buqvz8uqTHdryyTi1awuOXUtG9Xa9MLxjvfwYlxqzCzyETduOIjbDAC41WmHksM5wsSqcxCiqvO0Qsk1OZjwOb96CE0GRyDN3Rrt+g9CzkUeZA7tEDzuJQ6clx8Pv6B7s8TmN6+FxMLT1QKPmLdGnVw80qmqvxsH1z5c8FymxQfDeuh3+yWZoP2AQOtZ3z4+Vy6hKgT5bsPnYVWTDGDXaDMLYbvXLlJyQtqRGXMCGjfsRnpqDSjVbY9zwLrCx0A5dJ59L/D3onDeOnLqEgEB/hEUkIM/UGc279ceIoV1Ry8WuUHupZIWSIUKGnFpwYBUW+P2C28p/es1s6mDV8M/g5OBU7KTqv1h/PLweX1/6WU2IlJQIEWpSwtG+2GTpcsPEhJzCl68+g98v56jrjN1bYfIr/8OkHi1gW+DLXfYnvUCirhzGj9/Pw+aj4drEiWldvPDtZ3ile331i7xgO9PSMxCfUHIShoiIiIiIiIiI6H6S+JW8ZB4BCWYKSTroExwlxdckPiZlJekgZQvGwvTxMPkrn5U18KnftqztEPp9SXn5XL+vsuyP6FEh97k8c/rnSu5vefb0z19R8jxIeSkrz0TBMvq65CX09ZT1mZHt5RmVvyU937JeXtJWfRuEPMeltZeKM5ql0L1XyUn2sHbF3mtHkJKnTqOkistOgmm2EVpUaVTsYsh7Wefp3gAWWca4FB+I6S0nF0uEpKSkqRfM2clBXdaTGyk5wQ9fPz8BG9REiBGqdJuCdUumY3CrBrC1tgLyshAZEYPUlFTcMrGCg60VHD3qoEPfkWhieQOnTl9Hek4CTu09B7M2ndGyso16I+jJsFzp6RnKnQOlTeWfwZ+IiIiIiIiIiKisJB6mj5lJwFJe+piaPlZWkKyTgKY+sFmwjH4b+UzqKE+QVb9tWdshZH3RfZVWluhRJfe0PvGgfy7u9mzpn4uSyhSsS15Fn+F70dddWhtkWV9G/xzLq6SyVLoSkyFW5pYwzTLEocgz+b1D5O+FOH84wgaN3euW+KUsF6tFtcYY02ggWtdqVqx3RmxcAuztbdXEREHSzefoslfxxR8RkPy0a9eX8Ns3T6OWs6N6QSXTFXV5DZ4b/Dy+WvsTzhk3x/A2VdX9yT48mnZEY8tg+BwJgiYvAaev3cbgQS1hXyARI6TNySmpsLW11q2hR4ncB5L5lPuFD3rFI0lR6Zkmf8v7DwYRERERERERERHR3ZTYf0aSDEOb9UZ7hya6NVoaZOMb37U46n86v/tQQRK8lIyUk52j+rdgMDM7Owc5ObnFhseSwGdC1D6s+tFXO9RV3SH4/tOx8LC7MymT2gVIuhmpS8o2edn5+5YyFhb2aD3uU7w6RtvenMu/4pvt19U2FiT7ljZIW/5J0tai5+ph9zC2Wa5n6KGFeGnCDPwRnKjeOxXRv3Xui+73n25HtiYGP01/Ei99vVsddu+fPgd3298/fS6IiIiIiIiIiIjo/ioxGSIJBntbe7zd5Vm4GNvr1mrF56bg5QNzsOfCQfUX+iUFCAsmQfQyNBpYWVnolu6QX4JfWL8ax7NlyQFPTP0fmrval1hHaaSspY0D+j37LLo5y5pc7Px1E0IzMoq1T9ogbXmQZJ/SgyFD2X9qaiqSYsMRl5CMtLS0fyXIWx7StmxNGsJCwpCaUfL1LYv7fYxSX3p6MH5dvh3GnQegt4eV2nugPKQOGXsvPT1dvRZyfQomVO53m/8KaU9cZCSi49L+0fbIvrIyUtXrnqbR9s5Ii4tGZGSc+l4+l2SURnl29OMX3m/GZs7oPqwnkndtwtbA2H8k2SX7kO8xeU5jwmKQnJys3hf6sRf1xx0XGvG3ngciIiIiIiIiIiL6d5UaTZZAc9NqDfF+2+fUydALSspLw6s+n2OR91qkpqWWKWiZmZkFc/PC9UhgMSsrHF4+vtoV9bpjSnc3tWdKeUlCxNa9Fwb1ra1d4XcOuwKTirVN2iBteVDkmCTBE3puJ+a9OgmPDx2GoaMnYfjIkRj8xCRMm7cOgdFxxXqtPCyk/TH+v2Pm009jwe6b+ZP+lJVsn5GahOD73HNDzlfM0U04HF0PIx9rog6PVl4SxL+2dxFen/wknprwJCY++TlOpmrvX0lSxVwPR+Z9bHN5ybmThM/Kt5/CE/M3q0H6f4pc55u7v8W4p9/FZv8Y9Xxsmz8Bo99egbD0dPUcRV/aihnPTMbcDWceyP0rQ59VajkKfZpGYt36w+pz9CDJMaWlRWPfD+9h8ohhGPnUeAx+fBSGT/kI+y5FqMco1yQl5Sg+mzgRC/aElvt5ICIiIiIiIiIioofDXX9aL0mJgc174s1mT8HMoMg8H7dz8I3fOoxd/zrOBFzI/5W9BA9LkpWdU+LE5Znp/gj3076v1qoVqlhYlKtXSEHS3uZdeqOSuhSIoABtELcgaYO05UGQY5cA7qWtc/HKtAU4nFod4196C0sWL8ayL2dhcu9aiDu8DlOem4vDN2KKte1hIMeQm6sdkuxWXvGh0O5Gyqanh2HZa2Mwb/u5+xYwl3qzslJxaJc30lu0Ric3+7/UKyQxcg8Wf7UdMc6tMG7UaEwc3wN1zczUpMOWTx/HyGVe0lVJt8W/Q+6JbLktCgwF90+QfeXmyY5vIU+5btKOLPUmyFHfSxIg6sIRnIuKgdfFgAeSFJDn3szMBi1aeyLlhA8ORxVPZt4vcryS8Nk9/3l89kcMWox7FUu/W4zvP56KJtm+mD3zKxy9qe0Vk/885D6YHjFERERERERERET04N01oizBSfkF/lMdRuD9llOK9RC5LZOqp13HyD9ex1Prp+GI3ymkpKaoQUYJhBcMZMqysZGRbklLAouaiBDE6JZbNWik/jr8nkoJSMq2Ng0boo5uOTg0rFgw1cTYWA1uPgiyr8iLP+ObpYdRqcdU/LzoXTw5tBca1quNes074okXP8bnC6ah2a0L+HLJLqQUGDJL/sr2kkyR81fSUESyrP+1upSVIL68JDAt6+Ql72V7WS9l9HUU3Vbq1+9HlstCttVvV3C/+s9kOTs7HWmaXOTlZKnHUrRM0WMsy75lu5SYwzh3MRedmjRT56MpqmC9BY+94D7ToqKRlOeEQaOGo9+QQeg9sD1slXtGzktGRq5yk2arbdKfJ3GvNsvnJV2TgmVKI9vI+ZHyUre8L42U1bdB/pZWv6zXXyN9nbJtUQXLyd+SyhQkicaGI2fju09m4edpQ2FmZpbffqmraH0ltU/Ky7nSt63gedaTZ9i9Sxc0zgvAwYORdz0nf4fUG3l2DTYeNsH4t9/B62P6oEHj2mjUfjBe+fh5NNdcxC9/+KltLEjaW57zVlDR4y9te1kn7ZMyBe9l/bkuuI2817enYFkiIiIiIiIiIiIqzGiWQve+RJIQkQBlw8p1UM+iKo6Fn4fmVuHheyT0Fp4Vi9+v78PPF7bjQrAfNOkZMDcyhdFtQzVYl5amgbOTg3YDHQncpUSdwbYNx5CgLDcaMBa9GzgVS4hIcE/KbdeVM63RAsPb1VYDsgV7kUg5TXY49vy4AzeVZbdW/TGyfc1Cw25J+YSEJDg6Fp4L5X7QaJKx9auPcTCnLT6YOQq1nB3Vfcs+5SXvzW2qonLORWzZFY7aAzqhlo2F2m4JZoZdOII/fv8NW3f6ICghB5XcHGFpapzfCyIrKwqn/ziIeGMnGCT4Y9vqpdjmdQmZZvao4myN3KxknNu3HRt/3YgDpwNgYuMBN0dzdfvs7Gh12wQTZxhl3sCRDeuwfqs3AiLS4ODuDBszE7Wc9lyfx4G9F+HUZgC6KNdD1ksgNjUpCif3b8bWdZtx4Fwg8mCOSsp+JTmRm5uB8/v34tS5i7hy/gpiDa1gkR6DsKhcuFd3gYlShwRrYy4fVa7jr+oxBoanwdLNCfa6fRe8lgVJADnKZyNWnriNx/43GI1cC0+uL/XGBpzGga0b8duWP3HENxAmlq5wsTdT642+cgjePudw7cp5XPCPgbGtJTQRN5W25SAn9jyOn7yMyxfO4maGBRxzkxASlAjnWpVhrmwriYfS2ixt0J9XuSaIv4qtK5diu/dl2FStB3eH0ns5yb0v1/z66QPY8utP2H3winodXWxycHb3bly3aYIne3qq94w8P/E3LuLApvXq8fndSIGxtRMcbUzUZ0X2IedByiXGXIPP5k3YsmkbvI8rz6GhBdxdbNRrpC8n5zMpPgCHN23C1k3K83ojE05VnJAbcgo7T8ejZd9eaORsicve6+GbVgPDB7eDnfKsZaeE4dKlIJg61YCrvbl6zS8e2IfAdCvYZgVhz9ZN2L5pp/L8a2Dj4QwHc9P86yr7lXlaLh/ajM3rN2Lv4StIzDaEq5MtLMxMC58nYzvcOLEJJ3KqYmSXBoWe3/tFrqvXitnYb9QRMyf3hJ2lpXpNpB0WtlXg7u6GWnVqoKaHk3KdbuLQRh9YtOqLeiYB2Pfbb/h9xyFcj8+GW2VnWCntl+O8G6k7NSkevj7bsFU5/j37TxR7xvXnSea0CTy+Gxt+/gX7Tsu97KJc61u4ctALQVm2qOpipdYp1zE5IQSn9it16p5J/X2vvy+IiIiIiIiIiIhI657JECFBNQmu1XSpij5V2uNCqB+isxN1nxYmw2ddzwjD3vDjWHNlG344tx4Lz/6CifUfh1MJCYjkyDPYoUtyNOg2Cn0aOxdLhogsTTgO/r4X4TnKNn6HsfZkAho1bwR3m8KBv7RkP+xZuQuhyvvKbQZhZPsaxYKpCYnJDyQZkhR/HL8vPQi7HqPwVNcGJfZgkLa6NO2FcWN6ob6DjbouNTYI6+a8iE9XH0BQhjEcTZJwZv8urN54BBqH6mhRy0U9vpSUs/jhzfk4Hx2OjWu2It7UHEmBp7B95584kWiDXJ/v8MWWazC3N0D0mWPYsGM3IuwaoENtZ6SlncdiZdvLGUnY/M1inEzMhcmtZFz22Yu1m47BokELNHSz0e6nSDJEArSR13bhi1dmYt2JEBjZ2eK2UmbL1q3YcToDnu3qwsogGXsWz8O2EwGISM9GWmI0Av2v4EKUMbr0aAqjnBwcXPI63l6wHYHKMTpZanDt4C6s2eiFFJe6aF2z5OsuJBFzZf9POBDiiFETesBdN5SatEsSCoeWvYZpX27B2fAM2JgZIDH4DDZt2oo9143Qo01N3Ni7DIs3H4bf9UgkSXIjPAj+Vy7hQrQhLCK3YdOBi4hMyEZWWgKCA6/iwiUN6g9qAwdlv3drc6vqjnfOa1oytvywFF43YhAdchW5tfqgYx3bEoPk2oB3DDbP/h9mrz2Em2mGML8Vh+PbNuBQkg2sIy8j2K4JJijnTYLovpvn4t2PV+FYRDac7Ixx88x+rN+4E/63KqNrEw/1vEki5Mr2uZj23hJ4X0uCuaUh0pV6/vhjO345Got2nZvA0dxMrS/0zBrMfGUedlwOR56JMZKCjmDthitwrZSHs1eT0bJv72LJEFtTU8QGbMe3s5cjtlp3dKxrB40mDOs/nYl9ITE4vuYnHIrJg/WtJJw8shcbNx2GUcNWaFrZVr1WcdHnsWTac/hutx9umdvDNCME+3Zuwc/7r6NBq6bwsLdSy2mvqzHCz27CoRBr9OvfGnbKvmV9aeR8SmJAEhxCn1gojZTPyLiB3au3wqTF4xjYogqSQy7g8MFTuKZcPzNHZ9SqXx+1q7qodWk0IWoyJNcyF3t++gX+OdYwSgnAQa/92PhnIGp1bIZqtpal7lPOeVTQAcx7YRpW+fgh19AStzXROHdwL9b8fgSWjVqhke7Zi4+5ih/fmowvt59FfI4RjNNCsXfzr/COAeL2LIdPdn30b1VVPYaAA8vw4VvzsOVsqPpMZt88iQ0bt2D3pXQ0blEfzlaFk8VERERERERERET/ZWVKhggJqknQ1dHWAUPq94CHoRN8Y/yL9RIpzdi6g+HsYF8sOJdtEIsjK7TJC41HU4zvXK/EX4Jb2NVFlwHtkBVwFBfD0pEb5YdtG/Yj2qk2OtZ2URMPEjSPPvsnVmw7hTRlm47DphRLrkiZ5JRUODrY6dbcP3HXvLFj90XU6jsWXRuWHNzXn0f9L/XVuTCWTMeSI4aY8MFcvD95GHr0GYje/XvAImgr1m3zg23LtmjoYoWMjBB4b/TBuWR7vPnlLDz9+CD0HPgYXGIPYOeBozif0xpfLXgHIwcMQvdBPYHLW7H9ZCa69G8J89xIeCnbnrmZhsHTZuP9qaPQt/9A9OrVDqYB25RzFoJmfVqjkrkZUqMv5CdDOtd3VCf1XjH9ffiYdcO3C97D2MH90b3fUPRq7wr/zWvgk1YTA9s0RPO+w9GrtycSjuyGYYcX8N1HL2HUoPawVo434M/5mLv2Gjo8/wHmvTwGPXr1Q8+hj6NGygGs2hCAOl1borqdNiBelAT6z/y5Eqcy62DC0A6wNzdXy0lAONp3NT7/7iRaTv4AX739FPoN6K8cU2/UNQrGwd0ngCad0afvYxj62FC0q5OL816xGPTBJ5jx3JPKeWqHJp2Gof+AAYD/Rpx3HY6fv3gHo0b3gLup6b3b3KUFnIxj1fPqGxqDxqNfx4L3X8S4CRPQrYGTeh+XdjxXNszG5ztj0OXpaZjz1iQMVK5Zr97tkHbgR2wPzsRt10YY370JYq6sx+dzd8F20KtY8uFk9OnTD70GP45mtjewdbUX8pq3RRNXa6TE7FP2/SuMe7+CpZ8+h4EDB6Knci5auabhwq4DCLNrjc5Km9KS/bFs5hfwte2Gz+a/j6dHDkFv5R7q6H4DP606hMRbFiUnQ5T7NTnSF/uV+8KxdT/1vsjJScLR7Ttx2j8WdUa9jjlvPoVe/QahWwcPhHjvxZ4wEwxTjuFWTjq2zX0Z62/Wx4dffYxnRwxE1z4DlOvSHGnev+AXfwsM6FQP5rpnQp7R2IteOHjdAr2GtEOle8wjJImQa3sX4IP3ViHMvhZa3iWxJuS+SU29iD9X+8CxYy+k7pyN6Ut3w8//Mk4f2Y/1m3YjMK8yuukSTZIMkefufEQWBr03F9MmDFbv/051suC7xxtXb9VG/9bVS92nPOPb576ObTmd8N13H2DCsMHoPWAwurSsicQzO7H5ujGG92gqX07Y9eXzWHvZDhOmf4z3nxuNvgOGoGvnxri5cRH2Rd+CY+226r4Sb+zCt5+sRnTjJ/DD529h+KB+6N7/cXSpn4Wjv2/BwUgb9FXOqdkD6FVDRERERERERET0KCrfLNQKCUpaW1ljTPuhOPDkKkxv+jQqmTjCQPnvbpKzU5GTW3xCbXOr+vBoqH0fcsYXYRqNGqwsSPYpgWW3mu0w7Yed+O6V7qgsnS6yw7Dhw+cx6KUluJaSrgaZL/nsQZS6VR3UqmtV7Jf5uXl5D2TYHZGXmYVsVELVqtpg/b2oQ+fEnobXwXC4dnkMY9tUhY2NDSwtLeFcqTr6PTcJngjGvl2+6rEJOZraXfqgUw1XWFtbw9bWFp6dO8BJOa5OAweigYsjrKysYG/vga6dWgFxIbgSla6eU9nWvlV/jO9UQ91W9uPoXh/9nhmN2mnnsetIrBqILkiWY45uwuEIezwxeRjqOdmriRwZosypeg8M6VsLfnv34Ypy3WR+GUtLCxgqh25obKq2Q8rJ8F57d/ggo3FvTO1VV92v1CGfez7xFNrhArbsCco/xqKk7dIDpCQO1Ttg8tMv4X9Dmqr1ynk3sbJHrT69UBtJ8POLUa+37MvczFi9S43NzNXjt7CwULeRz0wkjm2kLSfry9TmvcGQ+WekToMGPfHGqLZwdHRU69Ynu4qSY5Hg+p4952DQpA9efbwVnJVrKPU7VK6HPk89hmrqJTBQz8fxTZtww6kdXhrXQt23HIu0r3av8ehYPQqbthxTkwHWDk3w+HNT8OLYbuo9JPe9sbEl3Nr2RX23PJz381N7TkT7bIZXnD1GTRmFVtWd1TqlvdU7Po0+LYv3ZLoXudZo0AMvD2+rHofUValmd3RtY4/cwCAEZGQgIfgPHDidg84jRqN9VSf1npCXvVMjDB7ZBXmnDsE7NKnQc6+eu6RUpCj3X9Hvg4Lks6ysUGz/+U/4J93Eb7/sQlRW1l23ETkJCUhV/obsXok/DQdg1U+rsHrtGixf8yNe7maHU78swDe7A9RzK+TZce30OMa28Mg/Z5VbDEZTD8AvIrzYc1OQXIe2g6fi3RcnoKGrk3pvyPWxq94C7VtWUc/TtfR0pCYdx9Fjaaje+wk82bGWug+5LyrXbImxb4xDdWUX8j0rbbq6eyfOpNfA088OQDWlTikn171a26cxurcLQo8fx4mYFPU7hoiIiIiIiIiIiP5CMkSoAWcTEzjY2WNKt3HwnrQGmwZ9jdFV+8DV2EGptHgQ+EZqGLKytMPY6Ek9ZmYe6NGluXaFnxfWHo3KD0AWJQFECf73nvodfv5pHnrXlKRGLnKtHOBsBKQknsauPwK1hRu2QP869sWSIdIGM9PyB33LwtDMFKaIQ1TY3YOxEqCUY5S/GVFBiNQATZo0VpMJ+gC6/HWo3BUN6gNXb96ApkCwtVbNGvm/QpdyptY2sFbeGxUZTsjYxFT5/0ykpGknapZPWrdqqQai9eXUc1q1OWrY5yEo6Eax4KkEeW9evYYUmCD61C6sXroMKxYtVl8/rViDMzdzAE04AsMydFsUpg1WByHkBuCQG4VNa3/K337l4qXYsukUkpXL4Xvdv9TArbTV3Nxct3SHtN3CuSE6DOsMk6QAeG/ZhpXfzMacjz/GooWbEK6USU8pHGQvi7K2+XyQtFmbZOrYqiPs7tGDQUjd2dlhiI4A6taoA5sC10KuqX31dqhXWVlQ1mVnK+f1RiZgmoLjv27Eyh+WaNug/N24bjeilFOfeCMIscq9ZGLugdb9B8LDJAbHdu3Arz98iTkffYwFX63E1USlnCZDvZYRN24gDx5o0tAhPyko+5d7wrN5a1lS15WVHHvtmg3haFnknrKyUe6LHGiUtqX4BeI6zJF94xB+Wr4i/1yuXroSe3xjYKxcKf9raYWuv3rNLExgfpceHkLb9qoYMn4A6ttXw6ix/eFW4JyWRD4zUL4D5Om4ke2BV5/vqyYUJJkgScjeL36AgdUz8Me+w0jXJeiktsb16+UnubT7rQRXN/Xju5LrWrPzAHSoZ4WrJw5g608/4uuPPsK8OXOw41yMcp6ykakce/rNYMTnGaFxvTv7EdpntA4qWygLyjq5jkEhQUDlGvCsbJf/HSfl5TukfvsOcM4LRXBw4XNKRERERERERET0X1Y4U1BOEnyToJ38grllHU98OuQtHHx6Lc49vQm7hy3B/Hav452mk/B2k4mwNjRHWnq6bss7JHjnOWYi2ktkEvFYs2gtrsSXHsDWBiHNULXFEMz/bQ++nv4hln48HGbKZ8eWf4s9sVLKGINGD0dVy+Lj+GdmZsHcXErff2ZOLrBDHqJj4koNQsr69Phg7N+2A1dupiA3KxfZcEJV98K9SeS9kZEFrCQHkJiElNxc9ZxoSxQ+pvIwMCh8yWU/hoZmMLYAAqMii513WY6Nj1HeJeDcUR/s8fLCbq8D6muv1z4cC0iCq71ynnNLb5P8Cl+GLUu4cRn7vL3zt9+jvLwOHUO0gQ1cTaCch5JJG52dXIGkJMTmaBM7Qs5lUvw1rHpnEkZPmo6FOw4gPDFXabT6saq0++heytJmF2OlnLY4zKxLnzOiKH2T3Ct75Aey9QrWkZsbj2SZmic2ELu8tfvXv/YpyzfSbeBmYYIspcKMjFj8+dVUjB3/Euas3okrkSmFj133Xv1/Fwe4KM9tUUZGf+G+UjYxNS49YaFeowR5KDNx8czRwveP9z4cOXcTRnaWMMwrnAiJl20cJcl574nAJalTr88r+G7dQkzt0zg/yVMaqd/ExkZNhqBaDdS3vdODTPZlYVEZVTyUBy8hEcm6+01aYGBU/OtS7RlzD9LDx3/vArw4bhxenbsCXpduIP1W4ftS9qHdjyUcHQv3KpL3RkZOyvesboVy1+XK6IQuTso9WHgoNnlvbGUNK6QiOiFbrZOIiIiIiIiIiIj+ZjKkIAkmSpJCEiOO9g5oUK0uRrYdhOe6jcfU7hPQu0lnZGUWHwZJtnN0641JzzaHGsL024DnZvyC8OTkUgN5asDP2Bh2jlUw6OnRqGF+C2fWv4PZK8+rn5s0Ho3XhtQuMSianq6BpYX8xPr+s3Rsipo1gDPHjyI2I6PE9ktgNGD3Enz23Q5cz9bA2MoMpohHSLB2KCs9eZ+dnYhECYa7OqvB64JBz78qISG+WKJGeiAkxAAN3d2L7UOWXZxdlXd1MGX+F1i1ZjXW/LRWfcmwQsuW/4jFS+diWFPXUttn4ugIW+Vvta6T1PL67eW1cvUqZfslWPb2CLWXREnkHqkivWE0CQiNvTNclpzLkys/xm/XzPDkJ99h7fef4b1ZH+LdD97H8y8Pg7tS5q+es7K0eem04bAy1Q69VR6Ghsr9awTcCAsrNLySXPPcXA2y1U42co87QXmUgAb9sUTZX9E2yLpl86egmnLegrZ+jYVeKej03If4dfmX+FA5DzM+/ACvvPE0GkgdBtpJxY3kkYiNQ1hG4bl+ZN8ZqZL+ub9knw7OLso7O4x4Y7ba7oLH8eOK5eq5fGVATbUHhbRD5iKJjMqEsUdlVCrS26kk8rkkZWX4sII9Kkojn5ua1kQVD3VJXVeQtCEzq+Rh2cpL6koM24Nl3+yGxnMs1q1ZhC9mz1Lv07dnzMCgFvJsaZna2cEMqcp3QVKhZ1TqSAv3Rbia6L2ttN8UZlbKhYyMRmh24YSHbJcZHY1ESbB6mOcneYiIiIiIiIiIiP7rHlikTIJwkoyQ4KS8ZC4JExNjpKUXH05Jeoe0mfghRjbW/lo92nsRRr+0EBfCY9WAd8Fgn56sk1dmejJ2L3oHb8/fg3j5wLQuXpn+JKpbWxcLBMq+pQ2mD2iYLEtLD/R5rAscQg5i2c6rSE9PV4OT+rZmZWUhxn83Vv96FtatOqJbFTvY1miDus7AwcMHkVSgvBx3jN8f8A02QrfWbe75a/eykPDq+QvnkKLR5O9H5pGIPX4MV/NM0aBRLTUgXZA6xE+LVqiMG7h6NUtNeMmcCfKSoPKRxS9h+KSvcVmpM59crtva+oWlZXM0bGKM4GvXkKFso99ehr5KifLCp+PH4ePN10sdHk3aYNusOZogHJcuJecnEKT+mLhYoFYrDG2inUNF6pTrHnfMB9d1ZcpMKasPQpelzZ8obc4r0KOhLOScWVg0Q8NGxrh+5WJ+0kxecvxxlw7jSrJSUDl/ZmZV0MJTuTmu38D17Dx1Xgj9PBJZGcFY9tI4TPz2gHpfxSvnIc+6IYZ2r6UOJSftlPOWFnQE/jKJjlKfnJfqrdoq1zIYvmcT1Guv37dGk4wzZy9KQWnmfWOg7NPOsyk8jRJw/kqU+l2gP5dyTwdtn4vRo2diT3iKWl7akhZ3CoFBQKdGze7LfV+UXANz88po4ukCXPWHb3ySeu711yAp6jj8LgMONWqgknK/3yu5cjdSZ1ZSHBLzLNGtV3u42NurSRv5zsvJjMA53zC1nOzD1q0T2jQ2hs8f23A+Ok6dJ0euUUpKCk5v3oJLUt+t2+p19fT0hFHsJXidjcn/jpR7NyMjCce9jyDFuRHa170zhBYREREREREREdF/3T8aKbO1sUZyskxbXJgE7OwcG+KVb1dghJoQyUPE0VUYMfJZzFyyHdejE5GRkaEGB+Wl0WiQmhSBU1tW481nhuGdH7wRI51OTOvihW8/w/9aVykxiCr7ljY8KLLP2r2nYnxnRxxcPgtTP1yI/ceuIS4hGVFXz2Lbj/Pw0cyFuGDoiTen9oe9Gtyuj8fHd4GN3w68K71FwuOVdibj+unfsXDuBoRV6Ybx/e7MEfJ3VU08g1mLvHEzUrefk79j8bID0NTqgzEdKhXbjyxXavEY+rU0wdal32PHmSA1OJsYF4Ojv8zCj/sS0PWJIWhkrh3mS4bcMlWqiLwZiOvBNxEdlwZTU2v0GPEYaoQdwMcLdyMkOk6tI+zyQaz8ZDHO2nfEhP5VSz1GNVDs2hnNmxrA68RJNfirZytjB4UGYP/VWG27EhNxdsvnmL/+JuxttNvei9puuV8ibuJ8cAgilXNjYmJVpjZLL4/ykH2Zmdmg57jHUSPkAD6SuiO0dUdePYA1iw4D0pNDIYmD5o9NQEsjX8yb9xsuhEap1ywq9CI2zp2FXQl18b9x7bQJKls7GKWF4tCZm2oZqc/v0Bp8M+8oIB0zlP3K+XVtNgz9mxtor+Up7bVMiI3G4Z9nY3ekNZy0u75v5Nl28OiPAX2r4srmlVhxwFe9RvK6uG8RFqw9B49eg9DHXblYCnVeEx8fXDaqi25d3e/bfV+UnNuWo55Fe+XcfvDBjzh6KRzJCRHw896ARbO/wfGc6pg4tota7u8ysbaFtVEGLp24hPD4JO21vnYcqz56H1dva3uGyH1haeOCIS++hdaZxzDtpffx7bJf8fuqRZj75mT8nOiJTpWUckaG6jmpMXAyBldJw7pvvsH241fVax4XHYg9P7yHn88YovfogahlpU1YEhEREREREREREWBwW35S/A8KCY2Ak6M9rK0sdWvukF82J8QGYM3M5/HD/lDk9xMwc0D9Jo1Rw7UyHOyTERkWj/DLlxCYcGeoH2P3LvhkwQcY3sRdDWAWDQJKr5D4hCRUryqDJz042l9nZ+Dclq+x9OfDuJF5ZxgkGJmhfrvheOfloajprJ3AWv3leFYWLv25AAuW7UewRl/eCG4Ne2D6W5PQvLqLejxJSYcxZ8THsH/lB0wfUlPdXvYXfm4NZr71E+q+pqwfpF0vv3AP3j4Xzyzwx7NffIp+HoGYO3YubJ6eiWY3lmOJVyS0Z0+7n3ffehrNa0jUHAg/r9T3hlKfbj8SfE2MC8aGz2Zgw9k43XYKE3t0GTkVMyd0VH/tLm2URMWVbfPx6ZIDiJScRbtnsHfWcPWzwEPL8c3XW3G1wDFaVWmNDz58Ee1qFk/EFCT1Bu/9Em98FYwXF36IfnW1M1fH3DiCRe99Cq+oXJhZWMMwWwPDyi3x3PMDcW3hRwhu+y4WPN9FPScRvmvx/pv70fPrORjv6Z7/q3kJwIeeWY1PZ/2qbVuV/vh50XNwVe6j6z4rSm1zG+W6pKYeK3ZN7kWuufziX+aR+GzBboTqcztGNmg7fAoaBn2J1cYTlfP2hHpOIi/vxDefLMaphDs9Z8wc62HKtLcwrJUkZAyRkhiInz6Ygd/9kmUCE9jcSoPGpgGemDwR5gfexY9GSn0fPaH2SEiI9ccvH81Uy+qPysytPV4eXQmbvz2JXl/PxYh6jtg8aygWR/TBzz+8AA9LS0RcWJt/X7wzuAYyM29iyQvPIbDNDCyY2lmtW8ixHf/heby3xQGf/z4D7ezs1DlNvH/4BN/v8UdG/qk0Q4OuT2LOqwPgbCuDkskwdjH4efpE7LR7Cr/OHKbeVw+K3FNRV3Zj8Wff45By/+iZubXCW++8iF6NK6vnNjn5SInXWBKzm2YNxg+3tee2pEn+9c+3z5rpWPTbJcTBFE6meYjPtUWnAeMxotJZvLEsI/88qd+BoZewY/0aHD0VgiRzJzTv9hhG9HXDppnTcbPNNHz3Qnf1Oy4u+gJ+/nQudl6OL/BMOmPIMy/h5cdaqe1hMoSIiIiIiIiIiEjrH0+GpKVlID6x9KSEPpngf2gdvl/wPbyvFRh+qSSWNTHk2Wfx5vje8HCwVYPHJQUA1SSMgz2srYsnYe43OaWSjJAgaFp0NDQwVE50rtJWV7g5mqm/5C/YRn15Ca6mxSUgUzkHJpb2cLQzUwOa+qC9nBspI4FQCchKHbKtBPNlXxKMLrhe6pTAtJRPTDyMOWPmwOmFBXhjQDVkpyQiJTMPhmY2cHawyN9PafXJvmVdZmo8klJz1OMxtXOFs13heRoKHru8l8/keEXRY7wFC7i52agBb/0xlkbqSk4OwOIXX0Cg5+v4/tVear2yXnoKpcUmQHNLezxy3uQz2Z/cD9IGIccl50OOq+B9oj9maZu8l8/0Qfh7tbmka1IWsp+Cdcsk6Fb2DrCxvDNviv68yT7kGNMTE5GRnQtjAxM4uNqr10x/HFKf1JURG4vU3FswMrGAg4OVWoccm5D3BcvKtUxOU86RrqycF2mT/JVjk3MlZfVB/qL3hZB69Oe44PmUbaW8/r6SY5B1WRmpSExKV0rlwNTKVb1W+v3JvkO8f8C7n57AwPmz8WSL0nsL3Q/STv25lechWaOcW1NL9Vzor68cU2nXWLaX8yH057Yk+vORmZKCxNR0tZylnb16rfXHLedJ1sdHRSHLQLketqbqfoXsMzHOC589+SUyh72H76Z2Us+Z1Ku/jvJMGsIcjq7aoeLKcy8SERERERERERH9F/zjyRARE5ug/P9tuLqUPCiPNEkfnE6LDcCR7X9gj18k0sMvIjjRHrUbe8DeozYe6/0YWjdyUQOXBYOxRcXEymwiBsr+HLUr/kFyLPpTLIHPe9EHQOVY7lcwU+qMizuIOaM/heMLC/Du43XVYKm0q7z7Ke/xlOSvHqPaO2T/l3jnyzBM/XEW+lZzyt9e367y1llWD+K66JW17rIcY3nOQ3nK3i/6fYqi+9Vo4rB++gQcqPQylr7eMz9B8E/4J85FwWMv6dmRxMqWWY/h+5udsGj+FNRzslfLyXq/bXMwa9k1PDZ7Hp5pVy0/GSXuVS8RERERERERERHh30mGiLDwaFhamsPRwU63pmTSPAmCS3JE/wt3+bW4BP30CZC7BS8TEpORkaFBFQ/tsEr/RRJsj48/iDmjPoXjywsxfUgt9dw9auRekF/Ry/0gv8SXe+CfCpbTgyf3qfSgkGsqPR/+a9dWvt9Cz63G+9PXIdK5ER7v1RZuVsYIv+oN76OBMGg5AT9+MBIOnAuEiIiIiIiIiIio3P61ZEhuXh7CI6JhY211z4TIXyWJkNS0dHi4V4LxAxxu52Enlzg93R8b5q2Dw+DnMbR1Jf6CnOgho0/2xQadxqZffsO58yFIVNZZujRA1/4DMa5fC1haWvLZJSIiIiIiIiIi+gv+tWSIkIRIVFQsTE1NSh0y66+SobGys3Ph5ub8n06E6Mlllh4V+l41/GU50cNJ30NGEiNC3wuO84AQERERERERERH9df9qMkRP5hDRZGbCydEe1lZ/b4LztPQMxCckwcLc/F+ZI4SIiIiIiIiIiIiIiB4uD0UyRKSlZSA+MUntxWFnZ1PupIgkQZKTU9XeJk4O9rC2/ntJFSIiIiIiIiIiIiIiqhgemmSIXkpKGlJS05CTkwsrKwuYm5vBzMxUTZLIEE9ChpHJyc1FVlY2MjOzkJ6ugYmJMWxtrGFra62WISIiIiIiIiIiIiIiEg9dMkQvOzsHGRqNmuzIUt7L+Pm3b2mbamBoCGNjI5iZmqjJEksLC3XeESIiIiIiIiIiIiIioqIe2mQIERERERERERERERHR/WCo+0tERERERERERERERFQhMRlCREREREREREREREQVGpMhRERERERERERERERUoTEZQkREREREREREREREFRqTIUREREREREREREREVKExGUJERERERERERERERBUakyFERERERERERERERFShMRlCREREREREREREREQVGpMhRERERERERERERERUgQH/BzdfU6OBCChVAAAAAElFTkSuQmCC)"
      ],
      "metadata": {
        "id": "DBaxOWm-3BY4"
      }
    }
  ]
}